零散笔记



# 1.java多线程:  Thread 、Runnable、Callable

​	**多线程编程优点**

​	1.进程之间不能共享内存，但线程之间共享内存非常容易

​	2.系统创建线程所分配的资源相对于创建进程而言，代价非常小。

​	**Java中实现多线程有3中方法**

​	1.继承Thread类

​	2.实现Runnable接口

​	3.实现Callable接口

​	

​	第一种实现---继承Thread类

继承Thread类，需要覆盖方法 run()方法，在创建Thread类的子类时需要重写 run(),加入线程所要执行的代即可。 

​	

```java
public class ThreadTest {
    public static void main(String[] args) throws Exception {
        new MyThread().start();
        new MyThread().start();
        new MyThread().start();
    }
}
class MyThread extends Thread{
    private int ticket = 5;

    @Override
    public void run() {
            for (int i = 0; i < 10; i++) {
                if(ticket>0){
                    System.out.println("车票第+" + ticket--+"张");
            }
        }
    }
}
```

这样代码的写法简单，符合大家的习惯，但是直接继承Thread类有一个很大的缺点，因为“java类的继承是单一的，extends后面只能指定一个父类”，所有如果当前类继承Thread类之后就不可以继承其他类。如果我们的类已经从一个类继承（如Swing继承自 Panle 类、JFram类等），则无法再继承 Thread 类，这时如果我们又不想建立一个新的类，应该怎么办呢？ 



第二种实现--实现Runnable接口



如果要实现多继承就得要用**implements**，Java 提供了接口 **java.lang.Runnable** 来解决上边的问题。

**Runnable**是可以共享数据的，多个Thread可以同时加载一个**Runnable**，当各自Thread获得CPU时间片的时候开始运行**Runnable**，**Runnable**里面的资源是被共享的，所以使用**Runnable**更加的灵活。



```java
public class ThreadRunnable {
    public static void main(String[] args) throws Exception {
        MyThread1 myThread1 = new MyThread1();
        new Thread( myThread1 ).start();
        new Thread( myThread1 ).start();
    }
}

class MyThread1 implements Runnable{
    private int ticket = 5;
    @Override
    public void run() {
            for (int i = 0; i < 10; i++) {
                if(ticket>0){
                    System.out.println("车票第+" + ticket--+"张");
            }
        }
    }
}


车票第+5张
车票第+2张
车票第+1张
车票第+3张
车票第+4张
```

1. 在第二种方法（**Runnable**）中，ticket输出的顺序并不是54321，这是因为线程执行的时机难以预测，ticket--并不是原子操作(关于原子操作后边会有详解)。
2. 在第一种方法中，我们new了3个Thread对象，即三个线程分别执行三个对象中的代码，因此便是三个线程去独立地完成卖票的任务；而在第二种方法中，我们同样也new了3个**Thread**对象，但只有一个**Runnable**对象，3个**Thread**对象共享这个**Runnable**对象中的代码，因此，便会出现3个线程共同完成卖票任务的结果。如果我们new出3个Runnable对象，作为参数分别传入3个**Thread**对象中，那么3个线程便会独立执行各自**Runnable**对象中的代码，即3个线程各自卖5张票。
3. 在第二种方法中，由于3个**Thread**对象共同执行一个**Runnable**对象中的代码，因此可能会造成线程的不安全，比如可能ticket会输出-1（如果我们System.out....语句前加上线程休眠操作，该情况将很有可能出现），这种情况的出现是由于，一个线程在判断ticket为1>0后，还没有来得及减1，另一个线程已经将ticket减1，变为了0，那么接下来之前的线程再将ticket减1，便得到了-1。这就需要加入同步操作（即互斥锁），确保同一时刻只有一个线程在执行每次for循环中的操作。而在第一种方法中，并不需要加入同步操作，因为每个线程执行自己Thread对象中的代码，不存在多个线程共同执行同一个方法的情况。



第三种实现---Callable接口

​	**Runnable**是执行工作的独立任务，但是它不返回任何值。如果你希望任务在完成的能返回一个值，那么可以实现**Callable**接口而不是**Runnable**接口。在Java SE5中引入的**Callable**是一种具有类型参数的泛型，它的参数类型表示的是从方法**call**()(不是**run**())中返回的值。 



​	

```java
public class ThreadCallable {
    public static void main(String[] args) throws Exception{
        MyThread2 myThread2 = new MyThread2();

        FutureTask<Integer> futureTask = new FutureTask<Integer>( myThread2 );
        new Thread( futureTask,"线程名：有返回值的线程2" ).start();

        System.out.println("子线程的返回值：" + futureTask.get());

    }
}
class MyThread2 implements Callable<Integer>{

    @Override
    public Integer call() throws Exception {
        System.out.println("当前线程名——" + Thread.currentThread().getName());
        int i = 0;
        for (; i < 5; i++) {
            System.out.println( "循环变量i的值：" + i );
        }
        return i;
    }
}



当前线程名——线程名：有返回值的线程2
循环变量i的值：0
循环变量i的值：1
循环变量i的值：2
循环变量i的值：3
循环变量i的值：4
子线程的返回值：5

Process finished with exit code 0

```





总结：

实现**Runnable**接口相比继承**Thread**类有如下优势： 

​	

1. 可以避免由于Java的单继承特性而带来的局限；
2. 增强程序的健壮性，代码能够被多个线程共享，代码与数据是独立的；
3. 适合多个相同程序代码的线程区处理同一资源的情况。



实现**Runnable**接口和实现**Callable**接口的区别: 

​	

1. Runnable是自从java1.1就有了，而Callable是1.5之后才加上去的
2. Callable规定的方法是call(),Runnable规定的方法是run()
3. Callable的任务执行后可返回值，而Runnable的任务是不能返回值(是void)
4. call方法可以抛出异常，run方法不可以
5. 运行Callable任务可以拿到一个Future对象，表示异步计算的结果。它提供了检查计算是否完成的方法，以等待计算的完成，并检索计算的结果。通过Future对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果。
6. 加入线程池运行，Runnable使用ExecutorService的execute方法，Callable使用submit方法。

![](/images/20181108113457.bmp)



# 2.Java锁--synchronized、Lock

**锁的类型**

1.可重入锁： 在执行对象中所有同步方法不用再次获取锁

2.可中断锁：再等待获取锁过程可中断

3.公平锁： 按等待获取锁的线程的等待时间进行获取，等待时间长的具有优先获取锁权利 

4.读写锁： 对资源读取和写入的时候拆分为2部分处理，读的时候可以多线程一起读，写的时候必须同步地写 



| 类别     | synchronized                                                 | lock                                                         |
| :------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 存在层次 | Java的关键字，在jvm层面上                                    | 是一个类                                                     |
| 锁的释放 | 1、以获取锁的线程执行完同步代码，释放锁 <br />2、线程执行发生异常，jvm会让线程释放锁 | 在finally中必须释放锁，不然容易造成线程死锁                  |
| 锁的获取 | 假设A线程获得锁，B线程等待。如果A线程阻塞，B线程会一直等待   | 分情况而定，Lock有多个锁获取的方式，具体下面会说道，大致就是可以尝试获得锁，线程可以不用一直等待 |
| 锁状态   | 无法判断                                                     | 可以判断                                                     |
| 锁类型   | 可重入 不可中断 非公平                                       | 可重入 可判断 可公平（两者皆可）                             |
| 性能     | 少量同步                                                     | 大量同步                                                     |



**synchronized**

```java
//修饰方法
public synchronized void method()
{
   // todo
}

//修饰代码块
public void method()
{
   synchronized(this) {
      // todo
   }
}

//修饰对象
public void method3(SomeObject obj)
{
   //obj 锁定的对象
   synchronized(obj)
   {
      // todo
   }
}



//修饰类
class ClassName {
   public void method() {
      synchronized(ClassName.class) {
         // todo
      }
   }
}
```

总结：

A. 无论synchronized关键字加在方法上还是对象上，如果它作用的对象是非静态的，则它取得的锁是对象；如果synchronized作用的对象是一个静态方法或一个类，则它取得的锁是对类，该类所有的对象同一把锁。 
B. 每个对象只有一个锁（lock）与之相关联，谁拿到这个锁谁就可以运行它所控制的那段代码。 

C. 实现同步是要很大的系统开销作为代价的，甚至可能造成死锁，所以尽量避免无谓的同步控制。



**Lock**

下是Lock接口的源码，修剪之后的结果： 

```java
public interface Lock {

    /**
     * Acquires the lock.
     */
    void lock();

    /**
     * Acquires the lock unless the current thread is
     * {@linkplain Thread#interrupt interrupted}.
     */
    void lockInterruptibly() throws InterruptedException;

    /**
     * Acquires the lock only if it is free at the time of invocation.
     */
    boolean tryLock();

    /**
     * Acquires the lock if it is free within the given waiting time and the
     * current thread has not been {@linkplain Thread#interrupt interrupted}.
     */
    boolean tryLock(long time, TimeUnit unit) throws InterruptedException;

    /**
     * Releases the lock.
     */
    void unlock();

    /**
     * Returns a new {@link Condition} instance that is bound to this
     * {@code Lock} instance.
     */
    Condition newCondition();
}
```

lock()：获取锁，如果锁被暂用则一直等待

unlock():释放锁

tryLock(): 注意返回类型是boolean，如果获取锁的时候锁被占用就返回false，否则返回true

tryLock(long time, TimeUnit unit)：比起tryLock()就是给了一个时间期限，保证等待参数时间

lockInterruptibly()：用该锁的获得方式，如果线程在获取锁的阶段进入了等待，那么可以中断此线程，先去做别的事



lock()

```java
public class LockTest {
    private Lock lock = new ReentrantLock();

    //需要参与同步的方法
    private void method(Thread thread){
        lock.lock();
        try {
            System.out.println("线程名"+thread.getName() + "获得了锁");
        }catch(Exception e){
            e.printStackTrace();
        } finally {
            System.out.println("线程名"+thread.getName() + "释放了锁");
            lock.unlock();
        }
    }

    public static void main(String[] args) {
        LockTest lockTest = new LockTest();

        //线程1
        Thread t1 = new Thread(new Runnable() {

            @Override
            public void run() {
                lockTest.method(Thread.currentThread());
            }
        }, "t1");

        Thread t2 = new Thread(new Runnable() {

            @Override
            public void run() {
                lockTest.method(Thread.currentThread());
            }
        }, "t2");

        t1.start();
        t2.start();
    }
}
//执行情况：线程名t1获得了锁
//         线程名t1释放了锁
//         线程名t2获得了锁
//         线程名t2释放了锁
```



trylock()

```java
public class LockTest {
    private Lock lock = new ReentrantLock();

    //需要参与同步的方法
    private void method(Thread thread){
/*      lock.lock();
        try {
            System.out.println("线程名"+thread.getName() + "获得了锁");
        }catch(Exception e){
            e.printStackTrace();
        } finally {
            System.out.println("线程名"+thread.getName() + "释放了锁");
            lock.unlock();
        }*/


        if(lock.tryLock()){
            try {
                System.out.println("线程名"+thread.getName() + "获得了锁");
            }catch(Exception e){
                e.printStackTrace();
            } finally {
                System.out.println("线程名"+thread.getName() + "释放了锁");
                lock.unlock();
            }
        }else{
            System.out.println("我是"+Thread.currentThread().getName()+"有人占着锁，我就不要啦");
        }
    }

    public static void main(String[] args) {
        LockTest lockTest = new LockTest();

        //线程1
        Thread t1 = new Thread(new Runnable() {

            @Override
            public void run() {
                lockTest.method(Thread.currentThread());
            }
        }, "t1");

        Thread t2 = new Thread(new Runnable() {

            @Override
            public void run() {
                lockTest.method(Thread.currentThread());
            }
        }, "t2");

        t1.start();
        t2.start();
    }
}

//执行结果： 线程名t2获得了锁
//         我是t1有人占着锁，我就不要啦
//         线程名t2释放了锁

```

ReentranyLock从源码可以看出在Lock中可以自己控制锁是否公平，而且，默认的是非公平锁，以下是ReentrantLock的构造函数： 

```java
public ReentrantLock() {
        sync = new NonfairSync();//默认非公平锁
    }
```





synchronized的底层实现：

我们知道java是用字节码指令来控制程序（这里不包括热点代码编译成机器码）。在字节指令中，存在有synchronized所包含的代码块，那么会形成2段流程的执行。 

![](/images/20181108135833.bmp)

我们点击查看SyncDemo.java的源码SyncDemo.class，可以看到如下： 

![](/images/20181108135923.bmp)

如上就是这段代码段字节码指令，没你想的那么难吧。言归正传，我们可以清晰段看到，其实synchronized映射成字节码指令就是增加来两个指令：monitorenter和monitorexit。当一条线程进行执行的遇到monitorenter指令的时候，它会去尝试获得锁，如果获得锁那么锁计数+1（为什么会加一呢，因为它是一个可重入锁，所以需要用这个锁计数判断锁的情况），如果没有获得锁，那么阻塞。当它遇到monitorexit的时候，锁计数器-1，当计数器为0，那么就释放锁。

那么有的朋友看到这里就疑惑了，那图上有2个monitorexit呀？马上回答这个问题：上面我以前写的文章也有表述过，synchronized锁释放有两种机制，一种就是执行完释放；另外一种就是发送异常，虚拟机释放。图中第二个monitorexit就是发生异常时执行的流程，这就是我开头说的“会有2个流程存在“。而且，从图中我们也可以看到在第13行，有一个goto指令，也就是说如果正常运行结束会跳转到19行执行。





Lock的底层实现：

Lock实现和synchronized不一样，后者是一种悲观锁，它胆子很小，它很怕有人和它抢吃的，所以它每次吃东西前都把自己关起来。而Lock呢底层其实是CAS乐观锁的体现，它无所谓，别人抢了它吃的，它重新去拿吃的就好啦，所以它很乐观。底层主要靠volatile和CAS操作实现的。





![](/images/20181108141042.bmp)

CAS:Compare and Swap, 比较并交换。 

CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。 



![](/images/20181108140850.bmp)



# 3.mysql索引 B+tree

B树是一种多路自平衡搜索树，它类似普通的二叉树，但是B书允许每个节点有更多的子节点。B树示意图如下： 

![](/images/20181108142706.bmp)

B树的特点： 

（1）所有键值分布在整个树中 

（2）任何关键字出现且只出现在一个节点中 

（3）搜索有可能在非叶子节点结束 

（4）在关键字全集内做一次查找，性能逼近二分查找算法 



B+树是B树的变体，也是一种多路平衡查找树，B+树的示意图为： 

![](/images/20181108142754.bmp)

从图中也可以看到，B+树与B树的不同在于： 

（1）所有关键字存储在叶子节点，非叶子节点不存储真正的data 

（2）为所有叶子节点增加了一个链指针 

为什么用B/B+树这种结构来实现索引呢？？ 

答：红黑树等结构也可以用来实现索引，但是文件系统及数据库系统普遍使用B/B+树结构来实现索引。mysql是基于磁盘的数据库，索引是以索引文件的形式存在于磁盘中的，索引的查找过程就会涉及到磁盘IO消耗，磁盘IO的消耗相比较于内存IO的消耗要高好几个数量级，所以索引的组织结构要设计得在查找关键字时要尽量减少磁盘IO的次数。为什么要使用B/B+树，跟磁盘的存储原理有关。

**局部性原理与磁盘预读** 

 为了提升效率，要尽量减少磁盘IO的次数。实际过程中，磁盘并不是每次严格按需读取，而是每次都会预读。磁盘读取完需要的数据后，会按顺序再多读一部分数据到内存中，这样做的理论依据是计算机科学中注明的局部性原理： 

```
当一个数据被用到时，其附近的数据也通常会马上被使用
程序运行期间所需要的数据通常比较集中
```

 （1）由于磁盘顺序读取的效率很高(不需要寻道时间，只需很少的旋转时间)，
 因此对于具有局部性的程序来说，预读可以提高I/O效率.预读的长度一般为页(page)的整倍数。
 （2）MySQL(默认使用InnoDB引擎),将记录按照页的方式进行管理,每页大小默认为16K(这个值可以修改)。linux 默认页大小为4K。



**为什么mysql的索引使用B+树而不是B树呢？？**
 （1）B+树更适合外部存储(一般指磁盘存储),由于内节点(非叶子节点)不存储data，所以一个节点可以存储更多的内节点，每个节点能索引的范围更大更精确。也就是说使用B+树单次磁盘IO的信息量相比较B树更大，IO效率更高。
 （2）mysql是关系型数据库，经常会按照区间来访问某个索引列，B+树的叶子节点间按顺序建立了链指针，加强了区间访问性，所以B+树对索引列上的区间范围查询很友好。而B树每个节点的key和data在一起，无法进行区间查找。

![](/images/20180824101539582.png)



# **4.缓存击穿、缓存雪崩、缓存穿透**



**缓存击穿**

​	缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。 

解决方案：

​	有很多种方法可以有效地解决缓存穿透问题，最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。另外也有一个更为简单粗暴的方法（我们采用的就是这种），如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。 



**缓存雪崩**

​	缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。 

解决方案：

​	缓存失效时的雪崩效应对底层系统的冲击非常可怕。大多数系统设计者考虑用加锁或者队列的方式保证缓存的单线程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。这里分享一个简单方案就是将缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。 



**缓存击穿**

​	对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。 

​	缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。 

解决方案：

1.使用互斥锁（mutex key）

​	业界比较常用的做法，是使用mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。 

​	SETNX，是「SET if Not eXists」的缩写，也就是只有不存在的时候才设置，可以利用它来实现锁的效果，所以这里给出两种版本代码参考： 

​	![](/images/20181108144840.bmp)

2.提前使用互斥锁

​	在value内部设置1个超时值(timeout1), timeout1比实际的memcache timeout(timeout2)小。当从cache读取到timeout1发现它已经过期时候，马上延长timeout1并重新设置到cache。然后再从数据库加载数据并设置到cache中。

3."永远不过期" 

​	这里的“永远不过期”包含两层意思：

(1) 从redis上看，确实没有设置过期时间，这就保证了，不会出现热点key过期问题，也就是“物理”不过期。

(2) 从功能上看，如果不过期，那不就成静态的了吗？所以我们把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建，也就是“逻辑”过期

从实战看，这种方法对于性能非常友好，唯一不足的就是构建缓存时候，其余线程(非构建缓存的线程)可能访问的是老数据，但是对于一般的互联网功能来说这个还是可以忍受。

4.资源保护

​	采用netflix的hystrix，可以做资源的隔离保护主线程池，如果把这个应用到缓存的构建也未尝不可。 

​	![](/images/20181108145704.bmp)



# 5.mysql优化

**概述**

MySQL数据库常见的两个瓶颈是：CPU和I/O的瓶颈。 

CPU在饱和的时候一般发生在**数据装入内存或从磁盘上读取数据时候**。 

磁盘I/O瓶颈发生在装入数据远大于内存容量的时候，如果应用分布在网络上，**那么查询量相当大的时候那么平瓶颈就会出现在网络上。** 

我们可以用mpstat, iostat, sar和vmstat来查看系统的性能状态。除了服务器硬件的性能瓶颈，对于MySQL系统本身，我们可以使用工具来优化数据库的性能。 



**mysql优化方案**

**Mysql的优化，大体可以分为三部分：索引的优化，sql语句的优化，表的优化** 



![](/images/20181108150941.bmp)

**索引优化**

1.索引

​	一般的应用系统，读写比例在10：1左右，而且插入操作和一般的更新操作很少出现性能问题，在生产环境中，我们遇到最多的也是最容易出现问题的，还是一些复杂的查询操作，因此对查询语句的优化是重中之重，**加速查询最好的方法就是索引。** 

​	索引：简单的说，相当于图书的目录，可以帮助用户快速的找到需要的内容。 

​	在MySQL中也叫做“键”，是存储引擎用于快速找到记录的一种数据结构。能够大大提高查询效率。特别是当数据量非常大，查询涉及多个表时，使用索引往往能使查询速度加快成千上万倍。 

总结：索引的目的在于提高查询效率，与我们查询图书所用的目录是一个道理：先定位到章，然后定位到该章下的一个小结，然后找到页数。相似的例子还有：查字典，查地图等。 

2. 索引类型

普通索引：是最基本的索引，它没有任何限制。 

唯一索引：与前面的普通索引类似，不同的就是：索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。

复合索引：指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。

主键索引：是一种特殊的唯一索引，一个表只能有一个主键，不允许有空值。一般是在建表的时候同时创建主键索引 

全文索引：主要用来查找文本中的关键字，而不是直接与索引中的值相比较。fulltext索引跟其它索引大不相同，它更像是一个搜索引擎，而不是简单的where语句的参数匹配。fulltext索引配合match against操作使用，而不是一般的where语句加like。它可以在create table，alter table ，create index使用，不过目前只有char、varchar，text 列上可以创建全文索引。值得一提的是，在数据量较大时候，现将数据放入一个没有全局索引的表中，然后再用CREATE index创建fulltext索引，要比先为一张表建立fulltext然后再将数据写入的速度快很多。 

3.索引优化

- 只要列中含有NULL值，就最好不要在此例设置索引，复合索引如果有NULL值，此列在使用时也不会使用索引
- 尽量使用短索引，如果可以，应该制定一个前缀长度
- 对于经常在where子句使用的列，最好设置索引，这样会加快查找速度
- 对于有多个列where或者order by子句的，应该建立复合索引
- 对于like语句，以%或者‘-’开头的不会使用索引，以%结尾会使用索引
- 尽量不要在列上进行运算（函数操作和表达式操作）
- 尽量不要使用not in和<>操作



**SQL慢查询优化**

![](/images/20181108151632.bmp)

1.如何捕获低效sql

​	1）slow_query_log 

​		这个参数设置为ON，可以捕获执行时间超过一定数值的SQL语句。 

​	2）ong_query_time 	

​		当SQL语句执行时间超过此数值时，就会被记录到日志中，建议设置为1或者更短。 

​	3）slow_query_log_file 

​		记录日志的文件名。 

​	4）log_queries_not_using_indexes 

​		这个参数设置为ON，可以捕获到所有未使用索引的SQL语句，尽管这个SQL语句有可能执行得挺快。 

2.慢查询优化的基本步骤

​	1)先运行看看是否真的很慢，注意设置SQL_NO_CACHE 

​	2）where条件单表查，锁定最小返回记录表。这句话的意思是把查询语句的where都应用到表中返回的记录数最小的表开始查起，单表每个字段分别查询，看哪个字段的区分度最高 

​	3)explain查看执行计划，是否与1预期一致（从锁定记录较少的表开始查询） 

​	4)order by limit 形式的sql语句让排序的表优先查 

​	5)了解业务方使用场景 

​	6)加索引时参照建索引的几大原则 

​	7)观察结果，不符合预期继续从1开始分析 

2.优化原则

- 查询时，能不要*就不用*，尽量写全字段名
- 大部分情况连接效率远大于子查询
- 多使用explain和profile分析查询语句
- 查看慢查询日志，找出执行时间长的sql语句优化
- 多表连接时，尽量小表驱动大表，即小表 join 大表
- 在千万级分页时使用limit
- 对于经常使用的查询，可以开启缓存



**数据库表优化**

- 表的字段尽可能用NOT NULL
- 字段长度固定的表查询会更快
- 把数据库的大表按时间或一些标志分成小表
- 将表拆分

数据表拆分：主要就是垂直拆分和水平拆分。 

水平切分:将记录散列到不同的表中，各表的结构完全相同，每次从分表中查询, 提高效率。 

垂直切分:将表中大字段单独拆分到另外一张表, 形成一对一的关系。 



#  6.HashMap和TreeMap

​	首先介绍一下什么是Map。在数组中我们是通过数组下标来对其内容索引的，而在Map中我们通过对象来对对象进行索引，用来索引的对象叫做key，其对应的对象叫做value。这就是我们平时说的键值对。 

​	HashMap通过hashcode对其内容进行快速查找，而 TreeMap中所有的元素都保持着某种固定的顺序，如果你需要得到一个有序的结果你就应该使用TreeMap（HashMap中元素的排列顺序是不固定的）。 

​	HashMap 非线程安全 TreeMap 非线程安全   HashTable是线程安全

​	**线程安全**

​	 在Java里，线程安全一般体现在两个方面： 

​	1、多个thread对同一个java实例的访问（read和modify）不会相互干扰，它主要体现在关键字synchronized。如ArrayList和Vector，HashMap和Hashtable （后者每个方法前都有synchronized关键字）。如果你在interator一个List对象时，其它线程remove一个element，问题就出现了。 

​	2.每个线程都有自己的字段，而不会在多个线程之间共享。它主要体现在java.lang.ThreadLocal类，而没有Java关键字支持，如像static、transient那样。 

​	**使用接口**

​	AbstractMap抽象类：(HashMap继承AbstractMap)覆盖了equals()和hashCode()方法以确保两个相等映射返回相同的哈希码。如果两个映射大小相等、包含同样的键且每个键在这两个映射中对应的值都相同，则这两个映射相等。映射的哈希码是映射元素哈希码的总和，其中每个元素是Map.Entry接口的一个实现。因此，不论映射内部顺序如何，两个相等映射会报告相同的哈希码。 

​	SortedMap接口：（TreeMap继承自SortedMap）它用来保持键的有序顺序。SortedMap接口为映像的视图(子集)，包括两个端点提供了访问方法。除了排序是作用于映射的键以外，处理SortedMap和处理SortedSet一样。添加到SortedMap实现类的元素必须实现Comparable接口，否则您必须给它的构造函数提供一个Comparator接口的实现。TreeMap类是它的唯一一份实现。 

​	**实现方式**

​	HashMap：基于哈希表实现。使用HashMap要求添加的键类明确定义了hashCode()和equals()[可以重写hashCode()和equals()]，为了优化HashMap空间的使用，您可以调优初始容量和负载因子 。

​	(1)HashMap(): 构建一个空的哈希映像 

​	(2)HashMap(Map m): 构建一个哈希映像，并且添加映像m的所有映射 

​	(3)HashMap(int initialCapacity): 构建一个拥有特定容量的空的哈希映像 

​	(4)HashMap(int initialCapacity, float loadFactor): 构建一个拥有特定容量和加载因子的空的哈希映像 



​	TreeMap：基于红黑树实现。TreeMap没有调优选项，因为该树总处于平衡状态。 

​	(1)TreeMap():构建一个空的映像树 

​	(2)TreeMap(Map m): 构建一个映像树，并且添加映像m中所有元素 

​	(3)TreeMap(Comparator c): 构建一个映像树，并且使用特定的比较器对关键字进行排序 

​	(4)TreeMap(SortedMap s): 构建一个映像树，添加映像树s中所有映射，并且使用与有序映像s相同的比较器排序 

​	

​	**性能对比**

​	HashMap：适用于在Map中插入、删除和定位元素。 

​	Treemap：适用于按自然顺序或自定义顺序遍历键(key)。 

​	HashMap通常比TreeMap快一点(树和哈希表的数据结构使然)，建议多使用HashMap，在需要排序的Map时候才用TreeMap。 

​	

# 7.设计模式概要

面向对象编程（Object Oriented Programming，*OOP*，面向对象程序设计） 

**OOP三大基本特性**

封装

​	封装，也就是把客观事物封装成抽象的类，并且类可以把自己的属性和方法只让可信的类操作，对不可信的进行信息隐藏。 

继承

​	继承是指这样一种能力，它可以使用现有的类的所有功能，并在无需重新编写原来类的情况下对这些功能进行扩展。 

多态

​	多态指一个类实例的相同方法在不同情形有不同的表现形式。具体来说就是不同实现类对公共接口有不同的实现方式，但这些操作可以通过相同的方式（公共接口）予以调用。 

**OOD七大原则**

​	面向对象设计（OOD）有**七**大原则，它们互相补充。 

​	

​	开-闭原则 

​		Open-Close Principle（OCP），即开-闭原则。开，指的是对扩展开放，即要支持方便地扩展；闭，指的是对修改关闭，即要严格限制对已有内容的修改。开-闭原则是最抽象也是最重要的OOD原则。简单工厂模式、工厂方法模式、抽象工厂模式中都提到了如何通过良好的设计遵循开-闭原则。 

​	

​	里氏替换原则

​		Liskov Substitution Principle（LSP），即里氏替换原则。该原则规定“子类必须能够替换其父类，否则不应当设计为其子类”。换句话说，父类出现的地方，都应该能由其子类代替。所以，子类只能去扩展基类，而不是隐藏或者覆盖基类。 



​	依赖倒置原则

​		Dependence Inversion Principle（DIP），依赖倒置原则。它讲的是“设计和实现要依赖于抽象而非具体”。一方面抽象化更符合人的思维习惯；另一方面，根据里氏替换原则，可以很容易将原来的抽象替换为扩展后的具体，这样可以很好的支持开-闭原则。 



​	接口隔离原则

​		Interface Segration Principle（ISP），接口隔离原则，“将大的接口打散成多个小的独立的接口”。由于Java类支持实现多个接口，可以很容易的让类具有多种接口的特征，同时每个类可以选择性地只实现目标接口。 



​	单一职责原则

​		Single Responsibility Principle（SRP），单一职责原则。它讲的是，不要存在多于一个导致类变更的原因，是高内聚低耦合的一个体现。 



​	迪米特法则/最少知道原则

​		Law of Demeter or Least Knowledge Principle（LoD or LKP），迪米特法则或最少知道原则。它讲的是“一个对象就尽可能少的去了解其它对象”，从而实现松耦合。如果一个类的职责过多，由于多个职责耦合在了一起，任何一个职责的变更都可能引起其它职责的问题，严重影响了代码的可维护性和可重用性。 



​	合成/聚合复用原则

 		Composite/Aggregate Reuse Principle（CARP / CRP），合成/聚合复用原则。如果新对象的某些功能在别的已经创建好的对象里面已经实现，那么应当尽量使用别的对象提供的功能，使之成为新对象的一部分，而不要再重新创建。新对象可通过向这些对象的委派达到复用已有功能的效果。简而言之，要尽量使用合成/聚合，而非使用继承。《Java设计模式（九） 桥接模式》中介绍的桥接模式即是对这一原则的典型应用。 

 	

​	**设计模式**

​	可以用一句话概括设计模式———设计模式是一种利用OOP的封闭、继承和多态三大特性，同时在遵循单一职责原则、开闭原则、里氏替换原则、迪米特法则、依赖倒置原则、接口隔离原则及合成/聚合复用原则的前提下，被总结出来的经过反复实践并被多数人知晓且经过分类和设计的可重用的软件设计方式。 

​	

​	

- 设计模式是高级软件工程师和架构师面试基本必问的项目（先通过面试进入这个门槛我们再谈其它）
- 设计模式是经过大量实践检验的安全高效可复用的解决方案。不要重复发明轮子，而且大多数时候你发明的轮子还没有已有的好
- 设计模式是被主流工程师/架构师所广泛接受和使用的，你使用它，方便与别人沟通，也方便别人code review（这个够实在吧）
- 使用设计模式可以帮你快速解决80%的代码设计问题，从而让你更专注于业务本身
- 设计模式本身是对几大特性的利用和对几大设计原则的践行，代码量积累到一定程度，你会发现你已经或多或少的在使用某些设计模式了
- 架构师或者team leader教授初级工程师设计模式，可以很方便的以大家认可以方式提高初级工程师的代码设计水平，从而有利于提高团队工程实力

GOF 23种设计模式

**1.创建型模式：抽象了对象实例化的过程，用来帮助创建对象的实例**

- Factory模式   （工厂模式）

- AbstractFactoy模式 (抽象工厂)

- Singleton模式 (单例)

- Builder模式 (创建者)

- Prototype模式（原型）

  **2.结构型模式：描述如何组合类和对象以获得更大的结构**

- Bridge模式   (桥接模式)

- Adapter模式   （适配器模式）

- Decorator模式 （装饰模式）

- Composite模式 （组合模式）

- Flyweight模式 （享元模式 ）

- Facade模式      (外观模式)

- Proxy模式   (代理模式)

  **3.行为型模式：描述算法和对象间职责的分配**

- Template模式   (模板方法模式)

- Strategy模式 （策略模式）

- State模式   (状态模式)

- Observer模式   (观察者模式)

- Memento模式 （备忘录模式）

- Mediator模式  (中介者模式)

- Command模式  (命令模式)

- Visitor模式 (访问者模式)

- Chain of Responsibility模式  (职责链模式)

- Iterator模式  （迭代器模式）

- Interpreter模式  （解释器模式）

# 8.mysql的四种事务隔离级别

​	**事务的基本要素（ACID）**

​	1.原子性（Atomicity） ：事务开始后所有操作，要么全部做完，要么全部不做，不可能停滞在中间环节。事务执行过程中出错，会回滚到事务开始前的状态，所有的操作就像没有发生一样。也就是说事务是一个不可分割的整体，就像化学中学过的原子，是物质构成的基本单位。

​	2.一致性（Consistency）：事务开始前和结束后，数据库的完整性约束没有被破坏 。比如A向B转账，不可能A扣了钱，B却没收到。 

​	3.隔离性（Isolation）：同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账。*

​	4.持久性（Durability）：事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚。



​	**事务并发的问题**

​	1、脏读：事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据

​	2、不可重复读：事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果不一致。

​	3、幻读：系统管理员A将数据库中所有学生的成绩从具体分数改为ABCDE等级，但是系统管理员B就在这个时候插入了一条具体分数的记录，当系统管理员A改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。

​	**小结：不可重复读的和幻读很容易混淆，不可重复读侧重于修改，幻读侧重于新增或删除。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表** 

​	

​	**MySQL的事务隔离级别**

​	

| 事务隔离级别                 | 脏读 | 不可重复读 | 幻读 |
| ---------------------------- | ---- | ---------- | ---- |
| 读未提交（read-uncommitted） | 是   | 是         | 是   |
| 读已提交（read-committed）   | 否   | 是         | 是   |
| 可重复读（repeatable-read）  | 否   | 否         | 是   |
| 串行化（serializable）       | 否   | 否         | 否   |

mysql默认的事务隔离级别为repeatable-read

![](/images/978383734.png)

**例子说明**

​	1.读未提交

​	（1）打开一个客户端A，并设置当前事务模式为read uncommitted（未提交读），查询表account的初始值： 

​	![](/images/367776221.png)

​	（2）在客户端A的事务提交之前，打开另一个客户端B，更新表account： 

​	![](/images/862399438.png)

​	（3）这时，虽然客户端B的事务还没提交，但是客户端A就可以查询到B已经更新的数据： 

​	![](/images/2059251412.png)

​	（4）一旦客户端B的事务因为某种原因回滚，所有的操作都将会被撤销，那客户端A查询到的数据其实就是脏数据： 

​	![](/images/1018252120.png)

（5）在客户端A执行更新语句update account set balance = balance - 50 where id =1，lilei的balance没有变成350，居然是400，是不是很奇怪，数据不一致啊，如果你这么想就太天真 了，在应用程序中，我们会用400-50=350，并不知道其他会话回滚了，要想解决这个问题可以采用读已提交的隔离级别 

​	![](/images/1023048699.png)

​	

​	2、读已提交 

​		1）打开一个客户端A，并设置当前事务模式为read committed（读已提交），查询表account的所有记录： 

​	![](/images/1441361659.png)

​	（2）在客户端A的事务提交之前，打开另一个客户端B，更新表account： 

​		![](/images/48081094.png)

​	（3）这时，客户端B的事务还没提交，客户端A不能查询到B已经更新的数据，解决了脏读问题： 

​	![](/images/179631977.png)

​	（4）客户端B的事务提交 

​		![](/images/1677223761.png)

  （5）客户端A执行与上一步相同的查询，结果 与上一步不一致，即产生了不可重复读的问题 

​	![](/images/2092924598.png)



3、可重复读 

​	（1）打开一个客户端A，并设置当前事务模式为repeatable read，查询表account的所有记录 

​		![](/images/1840487787.png)

​	2）在客户端A的事务提交之前，打开另一个客户端B，更新表account并提交 

![](/images/1495989601.png)

（3）在客户端A查询表account的所有记录，与步骤（1）查询结果一致，没有出现不可重复读的问题 

​	![](/images/1000794949.png)

​	（4）在客户端A，接着执行update balance = balance - 50 where id = 1，balance没有变成400-50=350，lilei的balance值用的是步骤（2）中的350来算的，所以是300，数据的一致性倒是没有被破坏。可重复读的隔离级别下使用了MVCC机制，select操作不会更新版本号，是快照读（历史版本）；insert、update和delete会更新版本号，是当前读（当前版本）。 

​	![](/images/1570431335.png)

​	（5）重新打开客户端B，插入一条新数据后提交 

​	![](/images/625875608.png)

​	（6）在客户端A查询表account的所有记录，没有 查出 新增数据，所以没有出现幻读 

​	![](/images/1606127377.png)



4.串行化 

​	（1）打开一个客户端A，并设置当前事务模式为serializable，查询表account的初始值： 

```mysql
mysql> set session transaction isolation level serializable;
Query OK, 0 rows affected (0.00 sec)

mysql> start transaction;
Query OK, 0 rows affected (0.00 sec)

mysql> select * from account;
+------+--------+---------+
| id   | name   | balance |
+------+--------+---------+
|    1 | lilei  |   10000 |
|    2 | hanmei |   10000 |
|    3 | lucy   |   10000 |
|    4 | lily   |   10000 |
+------+--------+---------+
rows in set (0.00 sec)
```

​	（2）打开一个客户端B，并设置当前事务模式为serializable，插入一条记录报错，表被锁了插入失败，mysql中事务隔离级别为serializable时会锁表，因此不会出现幻读的情况，这种隔离级别并发性极低，开发中很少会用到。 

```mysql
mysql> set session transaction isolation level serializable;
Query OK, 0 rows affected (0.00 sec)

mysql> start transaction;
Query OK, 0 rows affected (0.00 sec)

mysql> insert into account values(5,'tom',0);
ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction
```



**补充：** 

​	**1、事务隔离级别为读提交时，写数据只会锁住相应的行** 

​	**2、事务隔离级别为可重复读时，如果检索条件有索引（包括主键索引）的时候，默认加锁方式是next-key 锁；如果检索条件没有索引，更新数据时会锁住整张表。一个间隙被事务加了锁，其他事务是不能在这个间隙插入记录的，这样可以防止幻读。** 

​	**3、事务隔离级别为串行化时，读写数据都会锁住整张表** 

​	**4、隔离级别越高，越能保证数据的完整性和一致性，但是对并发性能的影响也越大。**



​	读未提交： 无锁

​	读已提交： 行锁

​	重复读    ： 间隙锁和表锁,根据有无索引

​	串行化     ： 表锁

​	锁等级越高，并发效率越差

# 9.Tomcat优化

![](/images/20181109144219.bmp)

**tomcat的3中运行模式**

|      | 时间   | CPU  | 内存 | 流量   |
| ---- | ------ | ---- | ---- | ------ |
| bio  | 23.354 | 50%  | 200  | 240.45 |
| nio  | 17.344 | 64%  | 150  | 325.16 |
| apr  | 13.755 | 52%  | 240  | 409.26 |

1、  bio 

​	默认的模式,性能非常低下,没有经过任何优化处理和支持. 一个线程处理一个请求。缺点：并发量高时，线程数较多，浪费资源。

Tomcat7或以下，在Linux系统中默认使用这种方式。

2、  nio 

​	nio(new I/O)，是Java SE 1.4及后续版本提供的一种新的I/O操作方式(即java.nio包及其子包)。Java nio是一个基于缓冲区、并能提供非阻塞I/O操作的Java API，因此nio也被看成是non-blocking I/O的缩写。它拥有比传统I/O操作(bio)更好的并发运行性能。

利用Java的异步IO处理，可以通过少量的线程处理大量的请求。

Tomcat8在Linux系统中默认使用这种方式。

Tomcat7必须修改Connector配置来启动：

<Connector port="8080"protocol="org.apache.coyote.http11.Http11NioProtocol"

​        connectionTimeout="20000" redirectPort="8443"/>

3、  apr 

​	安装起来最困难,但是从操作系统级别来解决异步的IO问题,大幅度的提高性能.即Apache PortableRuntime，从操作系统层面解决io阻塞问题。Tomcat7或Tomcat8在Win7或以上的系统中启动默认使用这种方式。Linux如果安装了apr和native，Tomcat直接启动就支持apr。具体安装办法 参见这个地址：<https://my.oschina.net/lsw90/blog/181161>

![](/images/20181109144803.bmp)



1.并发优化

​	默认的tomcat没有启用线程池， 在tomcat中每一个用户请求都是一个线程，所以可以使用线程池提高性能。这里前台其实有一个调度线程，然后调度线程会放入线程池内，然后到到一定的时候线程池的任务变成工作线程啊。 

​	开启并且使用：

​	![](/images/20170207172414647.png)

![](/images/20170207172424917.png)

参数说明：

​	![](/images/20181109151548.bmp)

最佳实践：

​	![](/images/20170207172502803.png)



​	

2.缓存优化

​	**Connector优化**

​		connector是连接器，负责接收客户的请求，以及向客户端回送响应的消息。所以 Connector的优化是重要部分。默认情况下 Tomcat只支持200线程访问，超过这个数量的连接将被等待甚至超时放弃，所以我们需要提高这方面的处理能力。 

​		修改这部分配置需要修改TOMCAT_HOME/conf/server.xml，打开server.xml找到Connector 标签项，默认配置如下： 

​		

```xml
<Connector port="8080"protocol="HTTP/1.1" 
          connectionTimeout="20000" 
          redirectPort="8443" /> 
```

​		其中port代表服务接口；protocol代表协议类型；connectionTimeout代表连接超时时间，单位为毫秒；redirectPort代表安全通信（https）转发端口，一般配置成443。 

​		可以看到除了这几个基本配置外并无特殊功能，所以我们需要对 Connector 进行扩展。

​       其中Connector 支持参数属性可以参考Tomcat官方网站（https://tomcat.apache.org/tomcat-8.0-doc/config/http.html），非常多，所以本文就只介绍些常用的。

​       我们将 Connector 配置修改为如下：

```xml
<Connector port="8080"  
         protocol="HTTP/1.1"  
         maxThreads="1000"  
         minSpareThreads="100"  
         acceptCount="1000" 
         maxConnections="1000" 
         connectionTimeout="20000"  
         maxHttpHeaderSize="8192" 
         tcpNoDelay="true" 
         compression="on" 
         compressionMinSize="2048" 
         disableUploadTimeout="true" 
         redirectPort="8443" 
         enableLookups="false" 
         URIEncoding="UTF-8" /> 
```

​	Connector是Tomcat接收请求的入口，每个Connector有自己专属的监听端口8088端口 接受http请求 

​	Connector有两种：HTTP Connector和AJPConnector 

​	![](/images/20181109152249.bmp)

![](/images/0181109152311.bmp)

![](/images/20181109152332.bmp)

![](/images/20181109152352.bmp)

![](/images/20181109152411.bmp)

![](/images/20181109152439.bmp)

![](/images/20181109152459.bmp)

![](/images/20181109152519.bmp)

![](/images/20181109152537.bmp)

![](/images/20181109152557.bmp)

![](/images/20181109152626.bmp)

![](/images/20181109152642.bmp)

![](/images/20181109152705.bmp)

![](/images/20181109152759.bmp)

![](/images/20181109152821.bmp)

![](/images/20181109152841.bmp)

​	最佳实践

​	![](/images/20170207172540163.png)

​	禁用AJP连接器

​	AJP（Apache JServerProtocol）

​	AJPv13协议是面向包的。WEB服务器和Servlet容器通过TCP连接来交互；为了节省SOCKET创建的昂贵代价，WEB服务器会尝试维护一个永久TCP连接到servlet容器，并且在多个请求和响应周期过程会重用连接。

​	![](/images/20170207172558210.png)

​	我们一般是使用Nginx+tomcat的架构，所以用不着AJP协议，所以把AJP连接器禁用。 

​	![](/images/20170207172613278.png)

​	![](/images/20181109153148.bmp)



3.内存优化

​	因为Tomcat运行在JAVA虚拟机之上,适当调整Tomcat的运行JVM参数可以提升整体性能。 

​	**JVM内存模式**

​	JVM一般回收对堆进行回收，以下是堆的分区

​	![](/images/20170207172654435.png)

​	◆ Young 年轻区（代） 

​		Young区被划分为三部分，Eden区和两个大小严格相同的Survivor区，其中，Survivor区间中，某一时刻只有其中一个是被使用的，另外一个留做垃圾收集时复制对象用，在Eden区间变满的时候， GC就会将存活的对象移到空闲的Survivor区间中，根据JVM的策略，在经过几次垃圾收集后，任然存活于Survivor的对象将被移动到Tenured区间。 

​	◆ Tenured 年老区 

​		Tenured区主要保存生命周期长的对象，一般是一些老的对象，当一些对象在Young复制转移一定的次数以后，对象就会被转移到Tenured区，一般如果系统中用了application级别(spring容器放在application)的缓存，缓存中的对象往往会被转移到这一区间。 

​	◆ Perm 永久区 

​		Perm代主要保存class,method,filed对象，这个区域不会被gc回收。这部份的空间一般不会溢出，除非一次性加载了很多的类，不过在涉及到热部署的应用服务器的时候，有时候会遇到java.lang.OutOfMemoryError : PermGen space 的错误，造成这个错误的很大原因就有可能是每次都重新部署，但是重新部署后，类的class没有被卸载掉，这样就造成了大量的class对象保存在了perm中，这种情况下，一般重新启动应用服务器可以解决问题。 

​	 tomcat热部署：是指在你修改项目BUG的时候对JSP或JAVA类进行了修改在不重启WEB服务器前提下能让修改生效。但是对配置文件的修改除外!  

​	Virtual区：虚拟区 

​	最大内存和初始内存的差值，就是Virtual区。 

​	

​	**设置区大小**

​	JVM提供了相应的参数来对内存大小进行配置。正如上面描述，JVM中堆被分为了3个大的区间，同时JVM也提供了一些选项对Young,Tenured的大小进行控制。

如何设置年轻代大小?哪些应用系统需要调整年轻代老年代  永久代？

 这个需要根据应用场景的特点设置啊，如果说我们需要经常创建对象啊  而且对象使用完后马上会被回收的，这种场景年轻代可以适当调大。

 比如说：对外提供一个查询数据的接口，返回数据  查询出来的对象转换成json对象  然后这个接口频繁访问  的我们可以适当调大一点。

 老年代：  静态变量什么的

​	![](/images/20170207172714257.png)

◆ Total Heap 

​	-Xms ：指定了JVM初始启动以后初始化内存 

​	-Xmx：指定JVM堆得最大内存，在JVM启动以后，会分配-Xmx参数指定大小的内存给JVM，但是不一定全部使用，JVM会根据-Xms参数来调节真正用于JVM的内存 

​	-Xmx -Xms之差就是三个Virtual空间的大小 

◆ Young Generation 

​	-XX:NewRatio=8意味着tenured 和 young的比值8：1，这样eden+2*survivor=1/9堆内存 

​	-XX:SurvivorRatio=32意味着eden和一个survivor的比值是32：1，这样一个Survivor就占Young区的1/34. 

​	-Xmn 参数设置了年轻代的大小 

◆ Perm Generation 

​	-XX:PermSize=16M -XX:MaxPermSize=64M 

Thread Stack 

​	-XX:Xss=128K 



**常用参数**

​	修改文件：bin/catalina.sh 

```xml
JAVA_OPTS="-Dfile.encoding=UTF-8-server –Xms512m -Xmx1024m -XX:NewSize=512m -XX:MaxNewSize=512m -XX:PermSize=256m-XX:MaxPermSize=256m -XX:NewRatio=2 -XX:MaxTenuringThreshold=50-XX:+DisableExplicitGC"
```

参数说明： 

​	1、  file.encoding 默认文件编码 

​	2、  -Xmx1024m  设置JVM最大可用内存为1024MB 	

​	3、  -Xms1024m  设置JVM最小内存为1024m。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。 

​	4、  -XX:NewSize  设置年轻代大小 

​	5、  XX:MaxNewSize 设置最大的年轻代大小 

​	6、  -XX:PermSize  设置永久代大小 

​	7、  -XX:MaxPermSize 设置最大永久代大小 

​	8、  -XX:NewRatio=4:设置年轻代（包括Eden和两个Survivor区）与终身代的比值（除去永久代）。设置为4，则年轻代与终身代所占比值为1：4，年轻代占整个堆栈的1/5 

​	9、  -XX:MaxTenuringThreshold=0：设置垃圾最大年龄，默认为：15。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概论。 

​	10、-XX:+DisableExplicitGC这个将会忽略手动调用GC的代码使得System.gc()的调用就会变成一个空调用，完全不会触发任何GC 

​	

​	Window设置

​	set JAVA_OPTS=-Dfile.encoding=UTF-8 -server-Xms1024m -Xmx2048m -XX:NewSize=512m -XX:MaxNewSize=1024m -XX:PermSize=256m-XX:MaxPermSize=256m -XX:MaxTenuringThreshold=10 -XX:NewRatio=2-XX:+DisableExplicitGC 	![](/images/20170207172741867.png)

​	Linux设置

​	修改bin/catalina.sh文件参数（第一行）

JAVA_OPTS="-Dfile.encoding=UTF-8-server -Xms1024m -Xmx2048m -XX:NewSize=512m -XX:MaxNewSize=1024m-XX:PermSize=256m -XX:MaxPermSize=256m -XX:MaxTenuringThreshold=10-XX:NewRatio=2 -XX:+DisableExplicitGC"

![](/images/20170207172751327.png)





server.xml配置

```xml
<?xml version='1.0' encoding='utf-8'?>
<!--
  Licensed to the Apache Software Foundation (ASF) under one or more
  contributor license agreements.  See the NOTICE file distributed with
  this work for additional information regarding copyright ownership.
  The ASF licenses this file to You under the Apache License, Version 2.0
  (the "License"); you may not use this file except in compliance with
  the License.  You may obtain a copy of the License at
      http://www.apache.org/licenses/LICENSE-2.0
  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!-- Note:  A "Server" is not itself a "Container", so you may not
     define subcomponents such as "Valves" at this level.
     Documentation at /docs/config/server.html
 -->
<Server port="8005" shutdown="SHUTDOWN">
  <Listener className="org.apache.catalina.startup.VersionLoggerListener" />
  <!-- Security listener. Documentation at /docs/config/listeners.html
  <Listener className="org.apache.catalina.security.SecurityListener" />
  -->
  <!--APR library loader. Documentation at /docs/apr.html -->
  <Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" />
  <!--Initialize Jasper prior to webapps are loaded. Documentation at /docs/jasper-howto.html -->
  <Listener className="org.apache.catalina.core.JasperListener" />
  <!-- Prevent memory leaks due to use of particular java/javax APIs-->
  <Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" />
  <Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" />
  <Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener" />
 
  <!-- Global JNDI resources
       Documentation at /docs/jndi-resources-howto.html
  -->
  <GlobalNamingResources>
    <!-- Editable user database that can also be used by
         UserDatabaseRealm to authenticate users
    -->
    <Resource name="UserDatabase" auth="Container"
              type="org.apache.catalina.UserDatabase"
              description="User database that can be updated and saved"
              factory="org.apache.catalina.users.MemoryUserDatabaseFactory"
              pathname="conf/tomcat-users.xml" />
  </GlobalNamingResources>
 
  <!-- A "Service" is a collection of one or more "Connectors" that share
       a single "Container" Note:  A "Service" is not itself a "Container",
       so you may not define subcomponents such as "Valves" at this level.
       Documentation at /docs/config/service.html
   -->
  <Service name="Catalina">
 
    <!--The connectors can use a shared executor, you can define one or more named thread pools-->
 
    <Executor name="tomcatThreadPool" namePrefix="catalina-exec-"
        maxThreads="800" minSpareThreads="100"  maxQueueSize="100" prestartminSpareThreads="true"/>
 
 
 
    <!-- A "Connector" represents an endpoint by which requests are received
         and responses are returned. Documentation at :
         Java HTTP Connector: /docs/config/http.html (blocking & non-blocking)
         Java AJP  Connector: /docs/config/ajp.html
         APR (HTTP/AJP) Connector: /docs/apr.html
         Define a non-SSL HTTP/1.1 Connector on port 8080
    -->
 
        <!--maxPostSize参数形式处理的最大长度，如果没有指定，该属性被设置为2097152（2兆字节）。上传提交的时候可以用的
            acceptCount请求的最大队列长度，当队列满时收到的任何请求将被拒绝
            acceptorThreadCount 用于接受连接的线程的数量
            disableUploadTimeout 禁用上传超时。
            maxConnections 服务器接受并处理的最大连接数
            SSLEnabled 在连接器上使用此属性来启用SSL加密传输
     -->
    <Connector executor="tomcatThreadPool" port="8080" protocol="org.apache.coyote.http11.Http11NioProtocol"
               connectionTimeout="20000"
               redirectPort="8443" 
                maxPostSize="10485760"
                acceptCount="100"
                acceptorThreadCount="2"
                disableUploadTimeout="true"
                maxConnections="10000"
                SSLEnabled="false"
    />
 
        <!-- A "Connector" using the shared thread pool-->
    <!--
    <Connector executor="tomcatThreadPool"
               port="8080" protocol="HTTP/1.1"
               connectionTimeout="20000"
               redirectPort="8443" />
    -->
    <!-- Define a SSL HTTP/1.1 Connector on port 8443
         This connector uses the BIO implementation that requires the JSSE
         style configuration. When using the APR/native implementation, the
         OpenSSL style configuration is required as described in the APR/native
         documentation -->
    <!--
    <Connector port="8443" protocol="org.apache.coyote.http11.Http11Protocol"
               maxThreads="150" SSLEnabled="true" scheme="https" secure="true"
               clientAuth="false" sslProtocol="TLS" />
    -->
 
    <!-- Define an AJP 1.3 Connector on port 8009 -->
    <Connector port="8009" protocol="AJP/1.3" redirectPort="8443" />
 
 
    <!-- An Engine represents the entry point (within Catalina) that processes
         every request.  The Engine implementation for Tomcat stand alone
         analyzes the HTTP headers included with the request, and passes them
         on to the appropriate Host (virtual host).
         Documentation at /docs/config/engine.html -->
 
    <!-- You should set jvmRoute to support load-balancing via AJP ie :
    <Engine name="Catalina" defaultHost="localhost" jvmRoute="jvm1">
    -->
    <Engine name="Catalina" defaultHost="localhost">
 
      <!--For clustering, please take a look at documentation at:
          /docs/cluster-howto.html  (simple how to)
          /docs/config/cluster.html (reference documentation) -->
      <!--
      <Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster"/>
      -->
 
      <!-- Use the LockOutRealm to prevent attempts to guess user passwords
           via a brute-force attack -->
      <Realm className="org.apache.catalina.realm.LockOutRealm">
        <!-- This Realm uses the UserDatabase configured in the global JNDI
             resources under the key "UserDatabase".  Any edits
             that are performed against this UserDatabase are immediately
             available for use by the Realm.  -->
        <Realm className="org.apache.catalina.realm.UserDatabaseRealm"
               resourceName="UserDatabase"/>
      </Realm>
 
      <Host name="localhost"  appBase="webapps"
            unpackWARs="true" autoDeploy="true">
 
        <!-- SingleSignOn valve, share authentication between web applications
             Documentation at: /docs/config/valve.html -->
        <!--
        <Valve className="org.apache.catalina.authenticator.SingleSignOn" />
        -->
 
        <!-- Access log processes all example.
             Documentation at: /docs/config/valve.html
             Note: The pattern used is equivalent to using pattern="common" -->
        <Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs"
               prefix="localhost_access_log." suffix=".txt"
               pattern="%h %l %u %t "%r" %s %b" />
 
      </Host>
    </Engine>
  </Service>
</Server>

```

# 10.Spring事务Transaction配置的五种注入方式详解

 	Spring配置文件中关于事务配置总是由三个组成部分，分别是DataSource、TransactionManager和代理机制这三部分，无论哪种配置方式，一般变化的只是代理机制这部分。 

​	DataSource、TransactionManager这两部分只是会根据数据访问方式有所变化，比如使用Hibernate进行数据访问时，DataSource实际为SessionFactory，TransactionManager的实现为HibernateTransactionManager。

​	 ![](/images/1404687232.png)

根据代理机制的不同，总结了五种Spring事务的配置方式，配置文件如下： 

​	**第一种方式：每个Bean都有一个代理**

​	 

```xml
<?xml version="1.0"encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xmlns:context="http://www.springframework.org/schema/context"
	xmlns:aop="http://www.springframework.org/schema/aop"
	xsi:schemaLocation="http://www.springframework.org/schema/beans
	http://www.springframework.org/schema/beans/spring-beans-2.5.xsd
	http://www.springframework.org/schema/context
	http://www.springframework.org/schema/context/spring-context-2.5.xsd
	http://www.springframework.org/schema/aop 				http://www.springframework.org/schema/aop/spring-aop-2.5.xsd">


<bean id="sessionFactory"
	class="org.springframework.orm.hibernate3.LocalSessionFactoryBean">
	<property name="configLocation" value="classpath:hibernate.cfg.xml" />
	<property name="configurationClass" value="org.hibernate.cfg.AnnotationConfiguration" />
</bean>
 
 <!-- 定义事务管理器（声明式的事务） -->
<bean id="transactionManager"
 	class="org.springframework.orm.hibernate3.HibernateTransactionManager">
	<property name="sessionFactory" ref="sessionFactory" />
</bean>

  
<!-- 配置DAO -->
<bean id="userDaoTarget" class="com.bluesky.spring.dao.UserDaoImpl">
	<property name="sessionFactory" ref="sessionFactory" />
</bean>

<bean id="userDao"
    class="org.springframework.transaction.interceptor.TransactionProxyFactoryBean">
	<!-- 配置事务管理器 -->
	<property name="transactionManager" ref="transactionManager" />
	<property name="target" ref="userDaoTarget" />
	<property name="proxyInterfaces" value="com.bluesky.spring.dao.GeneratorDao" />
 	<!-- 配置事务属性 -->
	<property name="transactionAttributes">
		<props>
			<prop key="*"> PROPAGATION_REQUIRED</prop>
		</props>
 	</property>
</bean>
</beans>
```

**第二种方式：所有Bean共享一个代理基类**

​	

```xml
<?xml version="1.0"encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xmlns:context="http://www.springframework.org/schema/context"
	xmlns:aop="http://www.springframework.org/schema/aop"
	xsi:schemaLocation="http://www.springframework.org/schema/beans
	http://www.springframework.org/schema/beans/spring-beans-2.5.xsd
	http://www.springframework.org/schema/context
	http://www.springframework.org/schema/context/spring-context-2.5.xsd
	http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-2.5.xsd">

    <bean id="sessionFactory"
		class="org.springframework.orm.hibernate3.LocalSessionFactoryBean">
		<property name="configLocation" value="classpath:hibernate.cfg.xml" />
		<property name="configurationClass" 	value="org.hibernate.cfg.AnnotationConfiguration" />
	</bean>
	<!-- 定义事务管理器（声明式的事务） -->
	<bean id="transactionManager"
		class="org.springframework.orm.hibernate3.HibernateTransactionManager">
		<property name="sessionFactory" ref="sessionFactory" />
	</bean>
 
	<bean id="transactionBase"
		class="org.springframework.transaction.interceptor.TransactionProxyFactoryBean"
		lazy-init="true" abstract="true">
		<!-- 配置事务管理器 -->
		<property name="transactionManager" ref="transactionManager" />
		<!-- 配置事务属性 -->
		<property name="transactionAttributes">
			<props>
				<prop key="*">PROPAGATION_REQUIRED </prop>
			</props>
		</property>
	</bean>
  
	<!-- 配置DAO -->
	<bean id="userDaoTarget" class="com.bluesky.spring.dao.UserDaoImpl">
		<property name="sessionFactory" ref="sessionFactory" />
	</bean>
  
	<bean id="userDao" parent="transactionBase">
		<property name="target" ref="userDaoTarget" />
	</bean>
</beans>

```

 **第三种方式：使用拦截器**

```xml
<?xml version="1.0"encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
		xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		xmlns:context="http://www.springframework.org/schema/context"
		xmlns:aop="http://www.springframework.org/schema/aop"
		xsi:schemaLocation="http://www.springframework.org/schema/beans
		http://www.springframework.org/schema/beans/spring-beans-2.5.xsd
		http://www.springframework.org/schema/context
		http://www.springframework.org/schema/context/spring-context-2.5.xsd
		http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-2.5.xsd">

	<bean id="sessionFactory"
		class="org.springframework.orm.hibernate3.LocalSessionFactoryBean">
		<property name="configLocation" value="classpath:hibernate.cfg.xml" />
		<property name="configurationClass" value="org.hibernate.cfg.AnnotationConfiguration" />
	</bean>
 
	<!-- 定义事务管理器（声明式的事务） -->
	<bean id="transactionManager"
		class="org.springframework.orm.hibernate3.HibernateTransactionManager">
		<property name="sessionFactory" ref="sessionFactory" />
    </bean>
  
	<bean id="transactionInterceptor"
		class="org.springframework.transaction.interceptor.TransactionInterceptor">
		<property name="transactionManager" ref="transactionManager" />
		<!-- 配置事务属性 -->
		<property name="transactionAttributes">
			<props>
				<prop key="*">PROPAGATION_REQUIRED </prop>
			</props>
		</property>
	</bean>
  
	<bean class="org.springframework.aop.framework.autoproxy.BeanNameAutoProxyCreator">
		<property name="beanNames">
			<list>
				<value> *Dao </value>
			</list>
		</property>
		<property name="interceptorNames">
			<list>
				<value> transactionInterceptor </value>
			</list>
        </property>
	</bean>
 
	<!-- 配置DAO -->
	<bean id="userDao" class="com.bluesky.spring.dao.UserDaoImpl">
		<property name="sessionFactory" ref="sessionFactory" />
	</bean>
</beans>
```

**第四种方式：使用tx标签配置的拦截器**

```xml
<?xml version="1.0"encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xmlns:context="http://www.springframework.org/schema/context"
	xmlns:aop="http://www.springframework.org/schema/aop"
	xmlns:tx="http://www.springframework.org/schema/tx"
	xsi:schemaLocation="http://www.springframework.org/schema/beans
	http://www.springframework.org/schema/beans/spring-beans-2.5.xsd
	http://www.springframework.org/schema/context
	http://www.springframework.org/schema/context/spring-context-2.5.xsd
	http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-2.5.xsd
	http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-2.5.xsd">
	<context:annotation-config />
	<context:component-scan base-package="com.bluesky" />
	
    <bean id="sessionFactory"
		class="org.springframework.orm.hibernate3.LocalSessionFactoryBean">
		<property name="configLocation" value="classpath:hibernate.cfg.xml" />
		<property name="configurationClass" value="org.hibernate.cfg.AnnotationConfiguration" />
	</bean>

    <!-- 定义事务管理器（声明式的事务） -->
	<bean id="transactionManager"
		class="org.springframework.orm.hibernate3.HibernateTransactionManager">
		<property name="sessionFactory" ref="sessionFactory" />
	</bean>

    
	<tx:advice id="txAdvice" transaction-manager="transactionManager">
		<tx:attributes>
			<tx:method name="*" propagation="REQUIRED" />
		</tx:attributes>
	</tx:advice>  

    <aop:config>
		<aop:pointcut id="interceptorPointCuts" 		            expression="execution(*com.bluesky.spring.dao.*.*(..))" />
		<aop:advisor advice-ref="txAdvice"  pointcut-ref="interceptorPointCuts" />
	</aop:config>
</beans>
```



**第五种方式：全注解** 

```xml
<?xml version="1.0"encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xmlns:context="http://www.springframework.org/schema/context"
	xmlns:aop="http://www.springframework.org/schema/aop"
	xmlns:tx="http://www.springframework.org/schema/tx"
	xsi:schemaLocation="http://www.springframework.org/schema/beans
	http://www.springframework.org/schema/beans/spring-beans-2.5.xsd
	http://www.springframework.org/schema/context
	http://www.springframework.org/schema/context/spring-context-2.5.xsd
	http://www.springframework.org/schema/aop 
     http://www.springframework.org/schema/aop/spring-aop-2.5.xsd
	http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-2.5.xsd">
	<context:annotation-config />
	<context:component-scan base-package="com.bluesky" />

    <tx:annotation-driven transaction-manager="transactionManager"/>
	
    <bean id="sessionFactory"
		class="org.springframework.orm.hibernate3.LocalSessionFactoryBean">
		<property name="configLocation" value="classpath:hibernate.cfg.xml" />
		<property name="configurationClass" value="org.hibernate.cfg.AnnotationConfiguration" />
	</bean>
	<!-- 定义事务管理器（声明式的事务） -->
	<bean id="transactionManager"   		class="org.springframework.orm.hibernate3.HibernateTransactionManager">
		<property name="sessionFactory" ref="sessionFactory" />
	</bean>
</beans>
```

 此时在DAO上需加上@Transactional注解，如下： 

```java
@Transactional
@Component("userDao")
public class UserDaoImpl extends HibernateDaoSupport implements UserDao {
	public List <User> listUsers() {
		return this .getSession().createQuery( " from User " ).list();
	}
}
```

# 11.Spring事务传播机制

Spring管理的事务可以分为如下两类：

1. 逻辑事务   在spring中定义的事务通常指逻辑事务，提供比物理事务更抽象，方便的事务配置管理，但也基于物理事务
2. 物理事务  特定于数据库的事务

Spring支持以下两种事务声明方式：

1. 编程式事务  当系统需要明确的，细粒度的控制各个事务的边界，应选择编程式事务
2. 声明式事务  当系统对于事务的控制粒度较粗时，应该选择申明式事务

​    无论你选择上述何种事务方式去实现事务控制，spring都提供基于门面设计模式的事务管理器供选择，如下是spring事务中支持的事务管理器:

| **事务管理器实现(org.springframework.\*)**    | **使用时机**                                                 |
| --------------------------------------------- | ------------------------------------------------------------ |
| jdbc.datasource.DataSourceTransactionManager  | 使用jdbc的抽象以及ibatis支持                                 |
| orm.hibernate.HibernateTransactionManager     | 使用hibernate支持(默认3.0以下版本)                           |
| orm.hibernate3.HibernateTransactionManager    | 使用hibernate3支持                                           |
| transaction.jta.JtaTransactionManager         | 使用分布式事务（分布式数据库支持）                           |
| orm.jpa.JpaTransactionManager                 | 使用jpa做为持久化工具                                        |
| orm.toplink.TopLinkTransactionManager         | 使用TopLink持久化工具                                        |
| orm.jdo.JdoTransactionManager                 | 使用Jdo持久化工具                                            |
| jms.connection.JmsTransactionManager          | 使用JMS 1.1+                                                 |
| jms.connection.JmsTransactionManager102       | 使用JMS 1.0.2                                                |
| transaction.jta.OC4JJtaTransactionManager     | 使用oracle的OC4J JEE容器                                     |
| transaction.jta.WebLogicJtaTransactionManager | 在weblogic中使用分布式数据库                                 |
| jca.cci.connection.CciLocalTransactionManager | 使用jrping对J2EE Connector Architecture (JCA)和Common Client Interface (CCI)的支持 |

![](/images/17e94d6b62e2.png)

各种事务管理器声明如下：

- JdbcTransactionManager定义如下

```xml
<bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager">  
          <property name="dataSource" ref="dataSource"/>  
</bean>  
```

- hibernate事务管理器配置如下

```xml
<bean id="transactionManager" class="org.springframework.orm.hibernate3.HibernateTransactionManager">  
    <property name="sessionFactory" ref="sessionFactory"/>
</bean>  
```

​	hibernate的事务管理器会注入session会话工厂，然后将事务处理委托给当前的transaction对象，事务提交时，调用commit()方法，回滚时调用rollback()方法

- jpa事务管理器配置如下

  ```xml
  <bean id="transactionManager" class="org.springframework.orm.jpa.JpaTransactionManager">  
  	<property name="entityManagerFactory" ref="entityManagerFactory"/>  
  </bean>  
  ```



**申明式事务配置**

​	spring特有的事务传播行为，spring支持7种事务传播行为，确定客户端和被调用端的事务边界（说得通俗一点就是多个具有事务控制的service的相互调用时所形成的复杂的事务边界控制）下图所示为7种事务传播机制。



| **传播行为**                                          | **含义**                                                     |
| ----------------------------------------------------- | ------------------------------------------------------------ |
| PROPAGATION_REQUIRED（XML文件中为REQUIRED)            | 表示当前方法必须在一个具有事务的上下文中运行，如有客户端有事务在进行，那么被调用端将在该事务中运行，否则的话重新开启一个事务。（如果被调用端发生异常，那么调用端和被调用端事务都将回滚） |
| PROPAGATION_SUPPORTS(XML文件中为SUPPORTS）            | 表示当前方法不必需要具有一个事务上下文，但是如果有一个事务的话，它也可以在这个事务中运行 |
| PROPAGATION_MANDATORY(XML文件中为MANDATORY）          | 表示当前方法必须在一个事务中运行，如果没有事务，将抛出异常   |
| PROPAGATION_NESTED(XML文件中为NESTED)                 | 表示如果当前方法正有一个事务在运行中，则该方法应该运行在一个嵌套事务中，被嵌套的事务可以独立于被封装的事务中进行提交或者回滚。如果封装事务存在，并且外层事务抛出异常回滚，那么内层事务必须回滚，反之，内层事务并不影响外层事务。如果封装事务不存在，则同PROPAGATION_REQUIRED的一样 |
| PROPAGATION_NEVER（XML文件中为NEVER)                  | 表示当方法务不应该在一个事务中运行，如果存在一个事务，则抛出异常 |
| PROPAGATION_REQUIRES_NEW(XML文件中为REQUIRES_NEW）    | 表示当前方法必须运行在它自己的事务中。一个新的事务将启动，而且如果有一个现有的事务在运行的话，则这个方法将在运行期被挂起，直到新的事务提交或者回滚才恢复执行。 |
| PROPAGATION_NOT_SUPPORTED（XML文件中为NOT_SUPPORTED） | 表示该方法不应该在一个事务中运行。如果有一个事务正在运行，他将在运行期被挂起，直到这个事务提交或者回滚才恢复执行 |

**事务隔离级别**

​	spring的事务隔离级别其实本质上是对SQL92标准的4种事务隔离级别的一种封装 

| **隔离级别**               | **含义**                                                     |
| -------------------------- | ------------------------------------------------------------ |
| ISOLATION_DEFAULT          | 使用数据库默认的事务隔离级别                                 |
| ISOLATION_READ_UNCOMMITTED | 允许读取尚未提交的修改，可能导致脏读、幻读和不可重复读       |
| ISOLATION_READ_COMMITTED   | 允许从已经提交的事务读取，可防止脏读、但幻读，不可重复读仍然有可能发生 |
| ISOLATION_REPEATABLE_READ  | 对相同字段的多次读取的结果是一致的，除非数据被当前事务自生修改。可防止脏读和不可重复读，但幻读仍有可能发生 |
| ISOLATION_SERIALIZABLE     | 完全服从ACID隔离原则，确保不发生脏读、不可重复读、和幻读，但执行效率最低。 |

**事务的只读属性**

​	spring事务只读的含义是指，如果后端数据库发现当前事务为只读事务，那么就会进行一系列的优化措施。它是在后端数据库进行实施的，因此，只有对于那些有可能启动一个新事务的传播行为（REQUIRED,REQUIRES_NEW,NESTED）的方法来说，才有意义。（测试表明，当使用JDBC事务管理器并设置当前事务为只读时，并不能发生预期的效果，即能执行删除，更新，插入操作）

**事务超时**

​	有的时候为了系统中关键部分的性能问题，它的事务执行时间应该尽可能的短。因此可以给这些事务设置超时时间，以秒为单位。我们知道事务的开始往往都会发生数据库的表锁或者被数据库优化为行锁，如果允许时间过长，那么这些数据会一直被锁定，影响系统的并发性。 

​	因为超时时钟是在事务开始的时候启动，因此只有对于那些有可能启动新事物的传播行为（REQUIRED,REQUIRES_NEW,NESTED）的方法来说，事务超时才有意义。

**事务回滚规则**

​	spring中可以指定当方法执行并抛出异常的时候，哪些异常回滚事务，哪些异常不回滚事务。

​	默认情况下，只在方法抛出运行时异常的时候才回滚(runtime exception)。而在出现受阻异常(checked exception)时不回滚事务，这个ejb的回滚行为一致。

​	当然可以采用申明的方式指定哪些受阻异常像运行时异常那样指定事务回滚。

# 12.防止SQL注入的五种方法

 **SQL注入简介**

​	SQL注入是比较常见的网络攻击方式之一，它不是利用操作系统的BUG来实现攻击，而是针对程序员编程时的疏忽，通过SQL语句，实现无帐号登录，甚至篡改数据库。 

**SQL注入攻击的总体思路** 

​	1.寻找到SQL注入的位置 

​	2.判断服务器类型和后台数据库类型 

​	3.针对不通的服务器和数据库特点进行SQL注入攻击 

**SQL注入攻击实例**

​	比如在一个登录界面，要求输入用户名和密码： 

​	可以这样输入实现免帐号登录： 

​	用户名： ‘or 1 = 1 –– 	 		

​	密 码： 

​	点登陆,如若没有做特殊处理,那么这个非法用户就很得意的登陆进去了.(当然现在的有些语言的数据库API已经处理了这些问题) 

​	这是为什么呢? 下面我们分析一下： 

​	从理论上说，后台认证程序中会有如下的SQL语句： 

​	String sql = "select * from user_table where username=' "+userName+" ' and password=' "+password+" '";	

​	当输入了上面的用户名和密码，上面的SQL语句变成： 

​	SELECT * FROM user_table WHERE username='’or 1 = 1 -- and password='’

​	分析SQL语句： 

​		条件后面username=”or 1=1 用户名等于 ” 或1=1 那么这个条件一定会成功； 

​	然后后面加两个-，这意味着注释，它将后面的语句注释，让他们不起作用，这样语句永远都能正确执行，用户轻易骗过系统，获取合法身份。 

​	这还是比较温柔的，如果是执行 SELECT * FROM user_table WHERE username='' ;DROP DATABASE (DB Name) --' and password=''

​	….其后果可想而知…  

**应对方法**

​	1.PreparedStatement

​		采用预编译语句集，它内置了处理SQL注入的能力，只要使用它的setXXX方法传值即可。 

​		使用好处： 

​			(1).代码的可读性和可维护性. 

​			(2).PreparedStatement尽最大可能提高性能. 

​			(3).最重要的一点是极大地提高了安全性. 

​		原理：

​			sql注入只对sql语句的准备(编译)过程有破坏作用 ，而PreparedStatement已经准备好了,执行阶段只是把输入串作为数据处理, 而不再对sql语句进行解析,准备,因此也就避免了sql注入问题. 

​	2.使用正则表达式过滤传入的参数

​		要引入的包：

​		import java.util.regex.*;

​		正则表达式：

​		private String CHECKSQL = “^(.+)\\sand\\s(.+)|(.+)\\sor(.+)\\s$”;

​		判断是否匹配：

​		Pattern.matches(CHECKSQL,targerStr);

​		下面是具体的正则表达式：

​		检测SQL meta-characters的正则表达式 ：

​			/(\%27)|(\’)|(\-\-)|(\%23)|(#)/ix

​		修正检测SQL meta-characters的正则表达式 ：/((\%3D)|(=))[^\n]*((\%27)|(\’)|(\-\-)|(\%3B)|(:))/i

​		典型的SQL 注入攻击的正则表达式 ：/\w*((\%27)|(\’))((\%6F)|o|(\%4F))((\%72)|r|(\%52))/ix

​		检测SQL注入，UNION查询关键字的正则表达式 ：/((\%27)|(\’))union/ix(\%27)|(\’)

​		检测MS SQL Server SQL注入攻击的正则表达式：

​		/exec(\s|\+)+(s|x)p\w+/ix

​		等等…..	

​	3.字符串过滤

​		比较通用的一个方法：（||之间的参数可以根据自己程序的需要添加）

​		public static boolean sql_inj(String str){

​			String inj_str = "'|and|exec|insert|select|delete|update|

​			count|*|%|chr|mid|master|truncate|char|declare|;|or|-|+|,";

​			String inj_stra[] = split(inj_str,"|");

​			for (int i=0 ; i &lt; inj_stra.length ; i++ ){

​			if (str.indexOf(inj_stra[i])&gt;=0){

​				return true;

​			}

​		}

​			return false;

​		}

​	4.JSP中调用该函数检查是否包含非法字符

​		防止SQL从URL注入： 

​		sql_inj.java代码：

​		package sql_inj;

​		import java.net.*;

​		import java.io.*;

​		import java.sql.*;

​		import java.text.*;

​		import java.lang.String;

​		public class sql_inj{

​			public static boolean sql_inj(String str){

​				String inj_str = "'|and|exec|insert|select|delete|update|

​			count|*|%|chr|mid|master|truncate|char|declare|;|or|-|+|,";

​		//这里的东西还可以自己添加

​			String[] inj_stra=inj_str.split("\\|");

​			for (int i=0 ; i &lt; inj_stra.length ; i++ ){

​			if (str.indexOf(inj_stra[i])&gt;=0){

​				return true;

​				}

​			}

​	return false;

​	}

​	}

5.JSP页面进行判断

​	使用javascript在客户端进行不安全字符屏蔽

功能介绍：检查是否含有”‘”,”\\”,”/”

参数说明：要检查的字符串

返回值：0：是1：不是

函数名是

function check(a){

return 1;

fibdn = new Array (”‘” ,”\\”,”/”);

i=fibdn.length;

j=a.length;

for (ii=0; ii＜i; ii++)

{ for (jj=0; jj＜j; jj++)

{ temp1=a.charAt(jj);

temp2=fibdn[ii];

if (tem’; p1==temp2)

{ return 0; }

}

}

return 1;

}

# 13.CSRF攻击原理和防御

​	1.CSRF是什么？

​	CSRF（Cross-site request forgery），中文名称：跨站请求伪造，也被称为：one click attack/session riding，缩写为：CSRF/XSRF。 

​	2.CSRF可以做什么？

​	你这可以这么理解CSRF攻击：攻击者盗用了你的身份，以你的名义发送恶意请求。CSRF能够做的事情包括：以你名义发送邮件，发消息，盗取你的账号，甚至于购买商品，虚拟货币转账......造成的问题包括：个人隐私泄露以及财产安全。 

​	3.CSRF漏洞现状

​	CSRF这种攻击方式在2000年已经被国外的安全人员提出，但在国内，直到06年才开始被关注，08年，国内外的多个大型社区和交互网站分别 爆出CSRF漏洞，如：NYTimes.com（纽约时报）、Metafilter（一个大型的BLOG网站），YouTube和百度HI......而 现在，互联网上的许多站点仍对此毫无防备，以至于安全业界称CSRF为“沉睡的巨人”。

 



4.CSRF攻击原理

​		![](/images/1548153978.jpg)

​	CSRF是什么呢？CSRF全名是Cross-site request forgery，是一种对网站的恶意利用，CSRF比XSS更具危险性。想要深入理解CSRF的攻击特性我们有必要了解一下网站session的工作原理。  

​	session我想大家都不陌生，无论你用.net或PHP开发过网站的都肯定用过session对象，然而session它是如何工作的呢？如果你不清楚请往下看。 

​	先问个小问题：如果我把浏览器的cookie禁用了，大家认为session还能正常工作吗？  

​	答案是否定的，我在这边举个简单的例子帮助大家理解session。  

​	比如我买了一张高尔夫俱乐部的会员卡，俱乐部给了我一张带有卡号的会员卡。我能享受哪些权利（比如我是高级会员卡可以打19洞和后付费喝饮料，而初级会员卡只能在练习场挥杆）以及我的个人资料都是保存在高尔夫俱乐部的数据库里的。我每次去高尔夫俱乐部只需要出示这张高级会员卡，俱乐部就知道我是谁了，并且为我服务了。 

​	这里我们的高级会员卡卡号 = 保存在cookie的sessionid；  而我的高级会员卡权利和个人信息就是服务端的session对象了。 

​	我们知道http请求是无状态的，也就是说每次http请求都是独立的无关之前的操作的，但是每次http请求都会将本域下的所有cookie作为http请求头的一部分发送给服务端，所以服务端就根据请求中的cookie存放的sessionid去session对象中找到该会员资料了。  

​	当然session的保存方法多种多样，可以保存在文件中，也可以内存里，考虑到分布式的横向扩展我们还是建议把它保存在第三方媒介中，比如redis或者mongodb。  

​	我们理解了session的工作机制后，CSRF也就很容易理解了。CSRF攻击就相当于恶意用户A复制了我的高级会员卡，哪天恶意用户A也可以拿着这张假冒的高级会员卡去高尔夫俱乐部打19洞，享受美味的饮料了，而我在月底就会收到高尔夫俱乐部的账单！  

​	了解CSRF的机制之后，危害性我相信大家已经不言而喻了，我可以伪造某一个用户的身份给其好友发送垃圾信息，这些垃圾信息的超链接可能带有木马程序或者一些欺骗信息（比如借钱之类的），如果CSRF发送的垃圾信息还带有蠕虫链接的话，那些接收到这些有害信息的好友万一打开私信中的连接就也成为了有害信息的散播着，这样数以万计的用户被窃取了资料种植了木马。整个网站的应用就可能在瞬间奔溃，用户投诉，用户流失，公司声誉一落千丈甚至面临倒闭。曾经在MSN上，一个美国的19岁的小伙子Samy利用css的background漏洞几小时内让100多万用户成功的感染了他的蠕虫，虽然这个蠕虫并没有破坏整个应用，只是在每一个用户的签名后面都增加了一句“Samy 是我的偶像”，但是一旦这些漏洞被恶意用户利用，后果将不堪设想，同样的事情也曾经发生在新浪微博上面。

​	举例：    

​	 CSRF攻击的主要目的是让用户在不知情的情况下攻击自己已登录的一个系统，类似于钓鱼。如用户当前已经登录了邮箱，或bbs，同时用户又在使用另外一个，已经被你控制的站点，我们姑且叫它钓鱼网站。这个网站上面可能因为某个图片吸引你，你去点击一下，此时可能就会触发一个js的点击事件，构造一个bbs发帖的请求，去往你的bbs发帖，由于当前你的浏览器状态已经是登陆状态，所以session登陆cookie信息都会跟正常的请求一样，纯天然的利用当前的登陆状态，让用户在不知情的情况下，帮你发帖或干其他事情。 



​	上面大概地讲了一下CSRF攻击的思想，下面我将用几个例子详细说说具体的CSRF攻击，这里我以一个银行转账的操作作为例子（仅仅是例子，真实的银行网站没这么傻:>） 

示例1：

​	银行网站A，它以GET请求来完成银行转账的操作，如：http://www.mybank.com/Transfer.php?toBankId=11&money=1000 

​	危险网站B，它里面有一段HTML的代码如下:

```html
<img src=http://www.mybank.com/Transfer.php?toBankId=11&money=1000>
```

​	首先，你登录了银行网站A，然后访问危险网站B，噢，这时你会发现你的银行账户少了1000块...... 

​	为什么会这样呢？原因是银行网站A违反了HTTP规范，使用GET请求更新资源。在访问危险网站B的之前，你已经登录了银行网站A，而B中 的<img>以GET的方式请求第三方资源（这里的第三方就是指银行网站了，原本这是一个合法的请求，但这里被不法分子利用了），所以你的浏 览器会带上你的银行网站A的Cookie发出Get请求，去获取资源“http://www.mybank.com /Transfer.php?toBankId=11&money=1000”，结果银行网站服务器收到请求后，认为这是一个更新资源操作（转账 操作），所以就立刻进行转账操作...... 

​	示例2:

​	为了杜绝上面的问题，银行决定改用POST请求完成转账操作。银行网站A的WEB表单如下：　　

```html
<form action="Transfer.php" method="POST">
　　　　<p>ToBankId: <input type="text" name="toBankId" /></p>
　　　　<p>Money: <input type="text" name="money" /></p>
　　　　<p><input type="submit" value="Transfer" /></p>
　　</form>
```

​	后台处理页面Transfer.php如下： 

```php
<?php
　　　　session_start();
　　　　if (isset($_REQUEST['toBankId'] &&　isset($_REQUEST['money']))
　　　　{
　　　　    buy_stocks($_REQUEST['toBankId'],　$_REQUEST['money']);
　　　　}
　　?>
```

​	危险网站B，仍然只是包含那句HTML代码： 

```html
　<img src=http://www.mybank.com/Transfer.php?toBankId=11&money=1000>
```

​	和示例1中的操作一样，你首先登录了银行网站A，然后访问危险网站B，结果.....和示例1一样，你再次没了1000块～T_T，这次事故的 原因是：银行后台使用了$_REQUEST去获取请求的数据，而$_REQUEST既可以获取GET请求的数据，也可以获取POST请求的数据，这就造成 了在后台处理程序无法区分这到底是GET请求的数据还是POST请求的数据。在PHP中，可以使用$_GET和$_POST分别获取GET请求和POST 请求的数据。在JAVA中，用于获取请求数据request一样存在不能区分GET请求数据和POST数据的问题。 

​	**示例3：**

　	经过前面2个惨痛的教训，银行决定把获取请求数据的方法也改了，改用$_POST，只获取POST请求的数据，后台处理页面Transfer.php代码如下：  

```php
<?php
　　　　session_start();
　　　　if (isset($_POST['toBankId'] &&　isset($_POST['money']))
　　　　{
　　　　    buy_stocks($_POST['toBankId'],　$_POST['money']);
　　　　}
　　?>
```

​	然而，危险网站B与时俱进，它改了一下代码： 

```html
<html>
　　<head>
　　　　<script type="text/javascript">
　　　　　　function steal()
　　　　　　{
          　　　　 iframe = document.frames["steal"];
　　     　　      iframe.document.Submit("transfer");
　　　　　　}
　　　　</script>
　　</head>

　　<body onload="steal()">
　　　　<iframe name="steal" display="none">
　　　　　　<form method="POST" name="transfer"　action="http://www.myBank.com/Transfer.php">
　　　　　　　　<input type="hidden" name="toBankId" value="11">
　　　　　　　　<input type="hidden" name="money" value="1000">
　　　　　　</form>
　　　　</iframe>
　　</body>
</html>
```

​	如果用户仍是继续上面的操作，很不幸，结果将会是再次不见1000块......因为这里危险网站B暗地里发送了POST请求到银行! 

​	总结一下上面3个例子，CSRF主要的攻击模式基本上是以上的3种，其中以第1,2种最为严重，因为触发条件很简单，一 个<img>就可以了，而第3种比较麻烦，需要使用JavaScript，所以使用的机会会比前面的少很多，但无论是哪种情况，只要触发了 CSRF攻击，后果都有可能很严重。

　　理解上面的3种攻击模式，其实可以看出，CSRF攻击是源于WEB的隐式身份验证机制！WEB的身份验证机制虽然可以保证一个请求是来自于某个用户的浏览器，但却无法保证该请求是用户批准发送的！



​	**5.CSRF防御**

- 通过 referer、token 或者 验证码 来检测用户提交。
- 尽量不要在页面的链接中暴露用户隐私信息。
- 对于用户修改删除等操作最好都使用post 操作 。
- 避免全站通用的cookie，严格设置cookie的域。



​	CSRF的防御可以从服务端和客户端两方面着手，防御效果是从服务端着手效果比较好，现在一般的CSRF防御也都在服务端进行。 

​	**1.服务端进行CSRF防御** 

​		服务端的CSRF方式方法很多样，但总的思想都是一致的，就是在客户端页面增加伪随机数。 

​	(1).Cookie Hashing(所有表单都包含同一个伪随机值)： 

​		这可能是最简单的解决方案了，因为攻击者不能获得第三方的Cookie(理论上)，所以表单中的数据也就构造失败了:>

```php
<?php
　　　　//构造加密的Cookie信息
　　　　$value = “DefenseSCRF”;
　　　　setcookie(”cookie”, $value, time()+3600);
　　?>
```

​	在表单里增加Hash值，以认证这确实是用户发送的请求。 

```php
<?php
　　　　$hash = md5($_COOKIE['cookie']);
　　?>
　　<form method=”POST” action=”transfer.php”>
　　　　<input type=”text” name=”toBankId”>
　　　　<input type=”text” name=”money”>
　　　　<input type=”hidden” name=”hash” value=”<?=$hash;?>”>
　　　　<input type=”submit” name=”submit” value=”Submit”>
　　</form>
```

​	然后在服务器端进行Hash值验证 

```php
<?php
　　      if(isset($_POST['check'])) {
     　　      $hash = md5($_COOKIE['cookie']);
          　　 if($_POST['check'] == $hash) {
               　　 doJob();
　　           } else {
　　　　　　　　//...
          　　 }
　　      } else {
　　　　　　//...
　　      }
      ?>
```

​	这个方法个人觉得已经可以杜绝99%的CSRF攻击了，那还有1%呢....由于用户的Cookie很容易由于网站的XSS漏洞而被盗取，这就 另外的1%。一般的攻击者看到有需要算Hash值，基本都会放弃了，某些除外，所以如果需要100%的杜绝，这个不是最好的方法。 

​	(2).验证码 



​	3).One-Time Tokens(不同的表单包含一个不同的伪随机值) 



​	4).WEB表单结构： 

```php
<?php
          session_start();
          include(”functions.php”);
     ?>
     <form method=”POST” action=”transfer.php”>
          <input type=”text” name=”toBankId”>
          <input type=”text” name=”money”>
          <? gen_input(); ?>
          <input type=”submit” name=”submit” value=”Submit”>
     </FORM>
```

​	5).服务端核对令牌： 

​	　这个很简单，这里就不再啰嗦了。

　　 上面这个其实不完全符合“并行会话的兼容”的规则，大家可以在此基础上修改



# 14.Spring容器、IOC、AOP、DI

​	我们是在使用Spring框架的过程中，其实就是为了使用IOC，依赖注入，和AOP，面向切面编程，这两个是Spring的灵魂。

​	主要用到的设计模式有工厂模式和代理模式。

​	IOC就是典型的工厂模式，通过sessionfactory去注入实例。

​	AOP就是典型的代理模式的体现。

​	代理模式是常用的java设计模式，他的特征是代理类与委托类有同样的接口，代理类主要负责为委托类预处理消息、过滤消息、把消息转发给委托类，以及事后处理消息等。代理类与委托类之间通常会存在关联关系，一个代理类的对象与一个委托类的对象关联，代理类的对象本身并不真正实现服务，而是通过调用委托类的对象的相关方法，来提供特定的服务。  

​	spring的IoC容器是spring的核心，spring AOP是spring框架的重要组成部分。

​	在传统的程序设计中，当调用者需要被调用者的协助时，通常由调用者来创建被调用者的实例。但在spring里创建被调用者的工作不再由调用者来完成，因此控制反转（IoC）；创建被调用者实例的工作通常由spring容器来完成，然后注入调用者，因此也被称为依赖注入（DI），依赖注入和控制反转是同一个概念。

​	面向方面编程（AOP)是以另一个角度来考虑程序结构，通过分析程序结构的关注点来完善面向对象编程（OOP）。OOP将应用程序分解成各个层次的对象，而AOP将程序分解成多个切面。spring AOP 只实现了方法级别的连接点，在J2EE应用中，AOP拦截到方法级别的操作就已经足够。在spring中，未来使IoC方便地使用健壮、灵活的企业服务，需要利用spring AOP实现为IoC和企业服务之间建立联系。 

​	IOC:控制反转也叫依赖注入。（Inversion of Control ）利用了工厂模式 将对象交给容器管理，你只需要在spring配置文件总配置相应的bean，以及设置相关的属性，让spring容器来生成类的实例对象以及管理对象。在spring容器启动的时候，spring会把你在配置文件中配置的bean都初始化好，然后在你需要调用的时候，就把它已经初始化好的那些bean分配给你需要调用这些bean的类（假设这个类名是A），分配的方法就是调用A的setter方法来注入，而不需要你在A里面new这些bean了。 

​	AOP:面向切面编程。（Aspect-Oriented Programming） AOP可以说是对OOP的补充和完善。OOP引入封装、继承和多态性等概念来建立一种对象层次结构，用以模拟公共行为的一个集合。当我们需要为分散的对象引入公共行为的时候，OOP则显得无能为力。也就是说，OOP允许你定义从上到下的关系，但并不适合定义从左到右的关系。例如日志功能。日志代码往往水平地散布在所有对象层次中，而与它所散布到的对象的核心功能毫无关系。在OOP设计中，它导致了大量代码的重复，而不利于各个模块的重用。 将程序中的交叉业务逻辑（比如安全，日志，事务等），封装成一个切面，然后注入到目标对象（具体业务逻辑）中去。 

​	实现AOP的技术，主要分为两大类：一是采用动态代理技术，利用截取消息的方式，对该消息进行装饰，以取代原有对象行为的执行；二是采用静态织入的方式，引入特定的语法创建“方面”，从而使得编译器可以在编译期间织入有关“方面”的代码. 

​	spring 的优点？ 1.降低了组件之间的耦合性 ，实现了软件各层之间的解耦  2.可以使用容易提供的众多服务，如事务管理，消息服务等  3.容器提供单例模式支持  4.容器提供了AOP技术，利用它很容易实现如权限拦截，运行期监控等功能  5.容器提供了众多的辅助类，能加快应用的开发  6.spring对于主流的应用框架提供了集成支持，如hibernate，JPA，Struts等  7.spring属于低侵入式设计，代码的污染极低  8.独立于各种应用服务器  9.spring的DI机制降低了业务对象替换的复杂性  10.Spring的高度开放性，并不强制应用完全依赖于Spring，开发者可以自由选择spring的部分或全部



​	什么是DI机制？  依赖注入（Dependecy Injection）和控制反转（Inversion of Control）是同一个概念，具体的讲：当某个角色  需要另外一个角色协助的时候，在传统的程序设计过程中，通常由调用者来创建被调用者的实例。但在spring中  创建被调用者的工作不再由调用者来完成，因此称为控制反转。创建被调用者的工作由spring来完成，然后注入调用者  因此也称为依赖注入。  spring以动态灵活的方式来管理对象 ， 注入的两种方式，设置注入和构造注入。  设置注入的优点：直观，自然  构造注入的优点：可以在构造器中决定依赖关系的顺序。

​	什么是AOP？  面向切面编程（AOP）完善spring的依赖注入（DI），面向切面编程在spring中主要表现为两个方面  1.面向切面编程提供声明式事务管理  2.spring支持用户自定义的切面 

​	



IOC的好处，初始化的过程中就不可避免的会写大量的new，只需要维护XML或注解，不需要大量的修改代码，IOC容器是分层的，从最底层BeanFactory网上找（后面源码解读会详细讲解），实现类与类之间的解耦合，可以将代码分离，每个人只需要写自己的部分，利于团队协作。 



使用IOC容器的小缺点: 引入第三方工具，对性能，初始化等速度均有影响，需要配置一大堆（springboot简化了好多，推荐大家从基于xml的spring学起），通过反射机制创建对象，效率较低~~~实际没影响。 

# 15.Filter、拦截器、AOP拦截的实现与区别

![](/images/484d129572258d9c.webp)

**Filter:**

​	AnimalFilter实现javax.servlet.Filter，项目启动时已初始化完成，可在控制台看到打印的初始化日志。 

​	

```java
@Component
public class AnimalFilter implements Filter {
 
    private Logger logger = LoggerFactory.getLogger(getClass());
 
    @Override
    public void init(FilterConfig filterConfig) throws ServletException {
        logger.info("animalFilter 初始化。。。");
    }
 
    @Override
    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {
        logger.info("animalFilter doFilter 。。。");
        chain.doFilter(request,response);//过滤器将请求往下传递
    }
 
    @Override
    public void destroy() {
        logger.info("animalFilter 销毁。。。");
    }
}
```

如何调用不被component修饰的filter，将上文中的component注解去除，通过下文方式，让注解生效并设置注解生效的url请求地址信息。 

```java
@Configuration
public class AnimalWebConfig {
    @Bean
    public FilterRegistrationBean animalFilter(){
        FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean();
        AnimalFilter animalFilter = new AnimalFilter();
        filterRegistrationBean.setFilter(animalFilter);
        List<String> urlPattern = new ArrayList<>();
        urlPattern.add("/animal/getAnimalById/*");
        filterRegistrationBean.setUrlPatterns(urlPattern);
        return filterRegistrationBean;
    }
}
```

​	由于filter获取的参数为ServletRequest request, ServletResponse response, FilterChain chain，无法知道是哪个类的那个方法调用，更无法知道调用时的参数。 



**Interceptor**:

​	首先编写一个AnimalInterceptor实现HandlerInteceptor方法，实现相应的三个方法，preHandle执行方法前执行返回的结果决定是否往下执行，postHandle当方法返回值时执行，afterCompletion无论成功或失败都将执行，前提是preHandler要返回true。

```java
@Component
public class AnimalInterceptor implements HandlerInterceptor {
 
    private Logger logger = LoggerFactory.getLogger(getClass());
 
    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
        HandlerMethod handlerMethod = (HandlerMethod) handler;
        String methodName = handlerMethod.getMethod().getName();
        logger.info("AnimalInterceptor:preHandle:methodName:" + methodName);
        logger.info("AnimalInterceptor:preHandle");
        return true;
    }
 
    @Override
    public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception {
        HandlerMethod handlerMethod = (HandlerMethod) handler;
        logger.info("AnimalInterceptor:preHandle:methodName:" + handlerMethod.getMethod().getName());
        logger.info("AnimalInterceptor:postHandle");
    }
 
    @Override
    public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception {
        logger.info("AnimalInterceptor:afterCompletion");
    }
}
```

将写好的AnimalInterceptor注入到spring的interceptor注册中心即可 

```java
@Component
public class InterceptorConfig extends WebMvcConfigurerAdapter{
 
    @Autowired
    AnimalInterceptor animalInterceptor;
 
    @Override
    public void addInterceptors(InterceptorRegistry registry) {
        registry.addInterceptor(animalInterceptor);
    }
}

```



**AOP**



```java
@Aspect
@Component
public class AnimalAspect {
    private Logger logger = LoggerFactory.getLogger(getClass());
 
    @Around("execution(* com.imooc.security.demo.web.controller..*.*(..))")
    public Object handleAnimalController(ProceedingJoinPoint proceedingJoinPoint) throws Throwable {
        Arrays.stream(proceedingJoinPoint.getArgs()).forEach(arg -> {
            logger.info("arg:"+arg);
        });
        logger.info("AnimalAspect");
        return proceedingJoinPoint.proceed();
    }
}

```

三个拦截器的比较如下，根据自己的业务功能需求选择最合适的拦截器。 



|      | Filter                                                       | Interceptor                                               | aspect                                               |
| ---- | ------------------------------------------------------------ | --------------------------------------------------------- | ---------------------------------------------------- |
| 参数 | ServletRequest, ServletResponse                              | HttpServletRequest , HttpServletResponse , Object handler | ProceedingJoinPoint                                  |
| 解释 | 可以拿到原始的http请求，但是拿不到你请求的控制器和请求控制器中的方法的信息 | 可以拿到你请求的控制器和方法，却拿不到请求方法的参数      | 可以拿到方法的参数，但是却拿不到http请求和响应的对象 |

**过滤器和拦截器的区别**

​	 过滤器可以简单的理解为“取你所想取”，过滤器关注的是web请求；拦截器可以简单的理解为“拒你所想拒”，拦截器关注的是方法调用，比如拦截 敏感词汇。 

- 拦截器是基于java反射机制来实现的，而过滤器是基于函数回调来实现的。（有人说，拦截器是基于动态代理来实现的 
- 拦截器不依赖servlet容器，过滤器依赖于servlet容器。 
- 拦截器只对Action起作用，过滤器可以对所有请求起作用。 
- 拦截器可以访问Action上下文和值栈中的对象，过滤器不能。 
- 在Action的生命周期中，拦截器可以多次调用，而过滤器只能在容器初始化时调用一次。 

# 16.Java内存模型

​	**概述**

​	多任务和高并发是衡量一台计算机处理器的能力重要指标之一。一般衡量一个服务器性能的高低好坏，使用每秒事务处理数（Transactions Per Second，TPS）这个指标比较能说明问题，它代表着一秒内服务器平均能响应的请求数，而TPS值与程序的并发能力有着非常密切的关系。在讨论Java内存模型和线程之前，先简单介绍一下硬件的效率与一致性。 

​	**硬件的效率和一致性**

​	由于计算机的存储设备与处理器的运算能力之间有几个数量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高速缓存（cache）来作为内存与处理器之间的缓冲：将运算需要使用到的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存之中没这样处理器就无需等待缓慢的内存读写了。 　　

​	基于高速缓存的存储交互很好地解决了处理器与内存的速度矛盾，但是引入了一个新的问题：缓存一致性（Cache Coherence）。在多处理器系统中，每个处理器都有自己的高速缓存，而他们又共享同一主存，如下图所示：多个处理器运算任务都涉及同一块主存，需要一种协议可以保障数据的一致性，这类协议有MSI、MESI、MOSI及Dragon Protocol等。Java虚拟机内存模型中定义的内存访问操作与硬件的缓存访问操作是具有可比性的，后续将介绍Java内存模型。 

​	![](/images/091102484251967.jpg)

​	除此之外，为了使得处理器内部的运算单元能竟可能被充分利用，处理器可能会对输入代码进行乱起执行（Out-Of-Order Execution）优化，处理器会在计算之后将对乱序执行的代码进行结果重组，保证结果准确性。与处理器的乱序执行优化类似，Java虚拟机的即时编译器中也有类似的指令重排序（Instruction Recorder）优化。 

**Java内存模型**

​	定义Java内存模型并不是一件容易的事情，这个模型必须定义得足够严谨，才能让Java的并发操作不会产生歧义；但是，也必须得足够宽松，使得虚拟机的实现能有足够的自由空间去利用硬件的各种特性（寄存器、高速缓存等）来获取更好的执行速度。经过长时间的验证和修补，在JDK1.5发布后，Java内存模型就已经成熟和完善起来了。 

​	**主内存和工作内存**

​		Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样底层细节。此处的变量与Java编程时所说的变量不一样，指包括了实例字段、静态字段和构成数组对象的元素，但是不包括局部变量与方法参数，后者是线程私有的，不会被共享。 

​		Java内存模型中规定**了所有的变量都存储在主内存中，每条线程还有自己的工作内存**（可以与前面将的处理器的高速缓存类比），线程的工作内存中保存了该线程使用到的变量到主内存副本拷贝，线程对变量的所有操作（读取、赋值）都必须在工作内存中进行，而不能直接读写主内存中的变量。不同线程之间无法直接访问对方工作内存中的变量，线程间变量值的传递均需要在主内存来完成，线程、主内存和工作内存的交互关系如下图所示，和上图很类似。 

​		![](/images/091134177063947.jpg)

​	这里的主内存、工作内存与Java内存区域的Java堆、栈、方法区不是同一层次内存划分。 

​	**内存间的交互操作**

​	关于主内存与工作内存之间的具体交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步到主内存之间的实现细节，Java内存模型定义了以下八种操作来完成： 

- lock（锁定）：作用于主内存的变量，把一个变量标识为一条线程独占状态。
- unlock（解锁）：作用于主内存变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。
- read（读取）：作用于主内存变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用
- load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。
- use（使用）：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。
- assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋值给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。
- store（存储）：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的 
- write（写入）：作用于主内存的变量，它把store操作从工作内存中一个变量的值传送到主内存的变量中。



​	如果要把一个变量从主内存中复制到工作内存，就需要按顺寻地执行read和load操作，如果把变量从工作内存中同步回主内存中，就要按顺序地执行store和write操作。Java内存模型只要求上述操作必须按顺序执行，而没有保证必须是连续执行。也就是read和load之间，store和write之间是可以插入其他指令的，如对主内存中的变量a、b进行访问时，可能的顺序是read a，read b，load b， load a。Java内存模型还规定了在执行上述八种基本操作时，必须满足如下规则： 

- 不允许read和load、store和write操作之一单独出现
- 不允许一个线程丢弃它的最近assign的操作，即变量在工作内存中改变了之后必须同步到主内存中。
- 不允许一个线程无原因地（没有发生过任何assign操作）把数据从工作内存同步回主内存中。
- 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量。即就是对一个变量实施use和store操作之前，必须先执行过了assign和load操作。
- 一个变量在同一时刻只允许一条线程对其进行lock操作，lock和unlock必须成对出现
- 如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前需要重新执行load或assign操作初始化变量的值
- 如果一个变量事先没有被lock操作锁定，则不允许对它执行unlock操作；也不允许去unlock一个被其他线程锁定的变量。
- 对一个变量执行unlock操作之前，必须先把此变量同步到主内存中（执行store和write操作）。



​	**Happens-before**

​		在内存模型中，如果一个操作执行的结果需要堆另一个操作可见，那么这两个操作之间必然存在happens-before关系。

​		Happens-before的规划：

- 程序顺序规则：单个线程中的每一个操作，总是前一个操作happens-before于该线程中的任意后续操作。
- 监视器规则：对一个锁的解锁，总是happens-before对整个锁的加锁。
- volatile变量规则：对一个volatile域的写，happens-before于任意后续对整个volatile域的读。
- 传递规则：  A happens-before B  ,  B happens-before C ,则 A happens- before C
- Start规则：
- Join规则： 



​	**重排序**

​	在执行程序时为了提高性能，编译器和处理器经常会对指令进行重排序。重排序分成三种类型： 

1. 编译器优化的重排序。编译器在不改变单线程程序语义放入前提下，可以重新安排语句的执行顺序。
2. 指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。
3. 内存系统的重排序。由于处理器使用缓存和读写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。



​	从Java源代码到最终实际执行的指令序列，会经过下面三种重排序： 

​	![](/images/091511346284594.png)



​	为了保证内存的可见性，Java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。Java内存模型把内存屏障分为LoadLoad、LoadStore、StoreLoad和StoreStore四种： 

​	![](/images/091516513623330.png)



​	**synchronized、volatile 、final内存语义**

​	

​		**volatile**

​		 volatile 定义的变量，特殊性在于： **一个线程对 volatile 变量的写一定对之后对这个变量的读的线程可见。**等价于 **一个线程对 volatile 变量的读一定能看见在它之前最后一个线程对这个变量的写。**

​		 为了实现这些语义，Java 规定，

​		（1）当一个线程要使用共享内存中的 volatile 变量时，如图中的变量a，它会直接从主内存中读取，而不使用自己本地内存中的副本。

​		（2）当一个线程对一个 volatile 变量进行写时，它会将这个共享变量的值刷新到共享内存中。 

​		其实 volatile 变量保证的是一个线程对它的写会立即刷新到主内存中，并置其它线程的副本为无效，它并不保证对 volatile 变量的操作都是具有原子性的。 

```java
public void add(){
     a++;         #1
 }

//等价于

public void add() {   
    temp = a;        
    temp = temp +1;  
    a = temp;         
 }
```

​	代码1并不是一个原子操作，所以类似于 a++ 这样的操作会导致并发数据问题。

​        volatile 变量的写被保证是可以被之后其他线程的读看到的，因此我们可以利用它进行线程间的通信。如：

```java
volatile int a;
public void set(int b) {
    a = b; 
}
public void get() {    
    int i = a; 
}
```

​	线程A执行set()后，线程B执行get()，相当于线程A向线程B发送了消息。 



​	**synchronized**

​	如果我们非要使用 a++ 这种复合操作进行线程间通信呢？java 为我们提供了synchronized。 

```java
public synchronized void add() {
    a++; 
 }
```

​	 synchronized 使得它作用范围内的代码对于不同线程是互斥的，并且线程在**释放锁的时候会将共享变量的值刷新到主内存**中。

​        我们可以利用这种互斥性来进行线程间通信。看下面的代码：

```java
public synchronized void add() {
    a++; 
}
public synchronized void get() {  
    int i = a; 
}
```

​	当线程A执行 add()，线程B调用get()，由于互斥性，线程A执行完add()后，线程B才能开始执行get()，并且线程A执行完add()，释放锁的时候，会将a的值刷新到共享内存中。因此线程B拿到的a的值是线程A更新之后的。 



​	**final变量**

​	final关键字可以修饰变量、方法和类，我们这里只讨论final修饰的变量。final变量的特殊之处在于：**final 变量一经初始化，就不能改变其值。** 

​	 这里的**值对于一个对象或者数组来说指的是这个对象或者数组的引用地址**。（因此可以通过对象反射去修改对象的值）因此，一个线程定义了一个final变量之后，其他任意线程都可以拿到这个变量。但有一点需要注意的是，当这个final变量为对象或者数组时， 

​	1、虽然我们**不能将这个变量赋值为其他对象或者数组的引用地址**，但是我们**可以改变对象的域或者数组中的元素**。 

​	2、线程对这个对象变量的域或者数据的元素的改变不具有线程可见性。 



​	**volatile和synchronized的比较**

​	根据以上的分析，我们可以发现volatile和synchronized有些相似。 

​	 1、当线程对 volatile变量写时，java 会把值刷新到共享内存中；而对于synchronized，指的是当线程释放锁的时候，会将共享变量的值刷新到主内存中。 

​	2、线程读取volatile变量时，会将本地内存中的共享变量置为无效；对于synchronized来说，当线程获取锁时，会将当前线程本地内存中的共享变量置为无效。 

​	 3、synchronized 扩大了可见影响的范围，扩大到了synchronized作用的代码块。 

​	

# 17.分布式算法（一致性Hash算法）

​	**分布式算法**

​	在做服务器负载均衡时候可供选择的负载均衡的算法有很多，包括： 轮循算法(Round Robin)、哈希算法(HASH)、最少连接算法(Least Connection)、响应速度算法(Response Time)、加权法(Weighted )等。其中哈希算法是最为常用的算法. 

​	 典型的应用场景是： 有N台服务器提供缓存服务，需要对服务器进行负载均衡，将请求平均分发到每台服务器上，每台机器负责1/N的服务。 

​	常用的算法是对hash结果取余数 (hash() mod N )：对机器编号从0到N-1，按照自定义的 hash()算法，对每个请求的hash()值按N取模，得到余数i，然后将请求分发到编号为i的机器。但这样的算法方法存在致命问题，如果某一台机器宕机，那么应该落在该机器的请求就无法得到正确的处理，这时需要将当掉的服务器从算法从去除，此时候会有(N-1)/N的服务器的缓存数据需要重新进行计算;如果新增一台机器，会有N /(N+1)的服务器的缓存数据需要进行重新计算。对于系统而言，这通常是不可接受的颠簸(因为这意味着大量缓存的失效或者数据需要转移)。那么，如何设计一个负载均衡策略，使得受到影响的请求尽可能的少呢? 

​	在Memcached、Key-Value Store 、Bittorrent DHT、LVS中都采用了Consistent Hashing算法，可以说Consistent Hashing 是分布式系统负载均衡的首选算法。 

​	**分布式缓存**

​	在大型web应用中，缓存可算是当今的一个标准开发配置了。在大规模的缓存应用中，应运而生了分布式缓存系统。分布式缓存系统的基本原理，大家也有所耳闻。key-value如何均匀的分散到集群中？说到此，最常规的方式莫过于hash取模的方式。比如集群中可用机器适量为N，那么key值为K的的数据请求很简单的应该路由到hash(K) mod N对应的机器。的确，这种结构是简单的，也是实用的。但是在一些高速发展的web系统中，这样的解决方案仍有些缺陷。随着系统访问压力的增长，缓存系统不得不通过增加机器节点的方式提高集群的相应速度和数据承载量。增加机器意味着按照hash取模的方式，在增加机器节点的这一时刻，大量的缓存命不中，缓存数据需要重新建立，甚至是进行整体的缓存数据迁移，瞬间会给DB带来极高的系统负载，设置导致DB服务器宕机。 那么就没有办法解决hash取模的方式带来的诟病吗？ 

​	假设我们有一个网站，最近发现随着流量增加，服务器压力越来越大，之前直接读写数据库的方式不太给力了，于是我们想引入Memcached作为缓存机制。现在我们一共有三台机器可以作为Memcached服务器，如下图所示： 

​	![](C:\Users\Administrator\Desktop\MD笔记\MD笔记\常用算法\images\1657885064.png)

​	很显然，最简单的策略是将每一次Memcached请求随机发送到一台Memcached服务器，但是这种策略可能会带来两个问题：一是同一份数据可能被存在不同的机器上而造成数据冗余，二是有可能某数据已经被缓存但是访问却没有命中，因为无法保证对相同key的所有访问都被发送到相同的服务器。因此，随机策略无论是时间效率还是空间效率都非常不好。 

​	要解决上述问题只需做到如下一点：保证对相同key的访问会被发送到相同的服务器。很多方法可以实现这一点，最常用的方法是计算哈希。例如对于每次访问，可以按如下算法计算其哈希值： 

```java
h = Hash(key) % 3
```

​	其中Hash是一个从字符串到正整数的哈希映射函数。这样，如果我们将Memcached Server分别编号为0、1、2，那么就可以根据上式和key计算出服务器编号h，然后去访问。

这个方法虽然解决了上面提到的两个问题，但是存在一些其它的问题。如果将上述方法抽象，可以认为通过：

```java
h = Hash(key) % N	
```

​	这个算式计算每个key的请求应该被发送到哪台服务器，其中N为服务器的台数，并且服务器按照0 – (N-1)编号。 

​	这个算法的问题在于容错性和扩展性不好。所谓容错性是指当系统中某一个或几个服务器变得不可用时，整个系统是否可以正确高效运行；而扩展性是指当加入新的服务器后，整个系统是否可以正确高效运行。 

​	现假设有一台服务器宕机了，那么为了填补空缺，要将宕机的服务器从编号列表中移除，后面的服务器按顺序前移一位并将其编号值减一，此时每个key就要按`h = Hash(key) % (N-1)`重新计算；同样，如果新增了一台服务器，虽然原有服务器编号不用改变，但是要按`h = Hash(key) % (N+1)`重新计算哈希值。因此系统中一旦有服务器变更，大量的key会被重定位到不同的服务器从而造成大量的缓存不命中。而这种情况在分布式系统中是非常糟糕的。 

​	一个设计良好的分布式哈希方案应该具有良好的单调性，即服务节点的增减不会造成大量哈希重定位。一致性哈希算法就是这样一种哈希方案。 

​	Hash 算法的一个衡量指标是单调性（ Monotonicity ），定义如下：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。 

​	容易看到，上面的简单 hash 算法 hash(object)%N 难以满足单调性要求 。

​	

​	**一致性哈希算法的理解**

​		**算法简述**

​			一致性哈希算法(Consistent Hashing Algorithm)是一种分布式算法，常用于负载均衡。Memcached client也选择这种算法，解决将key-value均匀分配到众多Memcached server上的问题。它可以取代传统的取模操作，解决了取模操作无法应对增删Memcached Server的问题(增删server会导致同一个key,在get操作时分配不到数据真正存储的server，命中率会急剧下降)。 

​			简单来说，一致性哈希将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0 - (2^32)-1（即哈希值是一个32位无符号整形），整个哈希空间环如下： 

​		                                        	![](C:\Users\Administrator\Desktop\MD笔记\MD笔记\常用算法\images\557607535.png)

​			 整个空间按顺时针方向组织。0和(2^32)-1在零点中方向重合。 	

​			  下一步将各个服务器使用H进行一个哈希，具体可以选择服务器的ip或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置，这里假设将上文中三台服务器使用ip地址哈希后在环空间的位置如下： 

​			                                    ![](C:\Users\Administrator\Desktop\MD笔记\MD笔记\常用算法\images\1023385076.png)

​			 接下来使用如下算法定位数据访问到相应服务器：将数据key使用相同的函数H计算出哈希值h，通根据h确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器。

​    例如我们有A、B、C、D四个数据对象，经过哈希计算后，在环空间上的位置如下：

​			                                	![](C:\Users\Administrator\Desktop\MD笔记\MD笔记\常用算法\images\314753840.png)

​				根据一致性哈希算法，数据A会被定为到Server 1上，D被定为到Server 3上，而B、C分别被定为到Server 2上。 

​	 	**容错性和可扩展分析**

​			下面分析一致性哈希算法的容错性和可扩展性。现假设Server 3宕机了： 

​			                                	![](C:\Users\Administrator\Desktop\MD笔记\MD笔记\常用算法\images\799563167.png)

​			可以看到此时A、C、B不会受到影响，只有D节点被重定位到Server 2。一般的，在一致性哈希算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即顺着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。

 			下面考虑另外一种情况，如果我们在系统中增加一台服务器Memcached Server 4： 

​				                               ![](C:\Users\Administrator\Desktop\MD笔记\MD笔记\常用算法\images\100001057.png)

​			此时A、D、C不受影响，只有B需要重定位到新的Server 4。一般的，在一致性哈希算法中，如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器（即顺着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。 

​			综上所述，一致性哈希算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。 



**虚拟节点**

​		一致性哈希算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜问题。例如我们的系统中有两台服务器，其环分布如下： 

​	                                         	![](C:\Users\Administrator\Desktop\MD笔记\MD笔记\常用算法\images\967737106.png)

​		此时必然造成大量数据集中到Server 1上，而只有极少量会定位到Server 2上。为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器ip或主机名的后面增加编号来实现。例如上面的情况，我们决定为每台服务器计算三个虚拟节点，于是可以分别计算“Memcached Server 1#1”、“Memcached Server 1#2”、“Memcached Server 1#3”、“Memcached Server 2#1”、“Memcached Server 2#2”、“Memcached Server 2#3”的哈希值，于是形成六个虚拟节点： 

​                                                	![](C:\Users\Administrator\Desktop\MD笔记\MD笔记\常用算法\images\1416349600.png)

**JAVA实现**

​	

```java
import java.security.MessageDigest;
import java.security.NoSuchAlgorithmException;
import java.util.Collection;
import java.util.SortedMap;
import java.util.TreeMap;

/**
 * 一致性Hash算法
 *
 * @param <T> 节点类型
 */
public class ConsistentHash<T> {
    /**
     * Hash计算对象，用于自定义hash算法
     */
    HashFunc hashFunc;
    /**
     * 复制的节点个数
     */
    private final int numberOfReplicas;
    /**
     * 一致性Hash环
     */
    private final SortedMap<Long, T> circle = new TreeMap<>();

    /**
     * 构造，使用Java默认的Hash算法
     * @param numberOfReplicas 复制的节点个数，增加每个节点的复制节点有利于负载均衡
     * @param nodes            节点对象
     */
    public ConsistentHash(int numberOfReplicas, Collection<T> nodes) {
        this.numberOfReplicas = numberOfReplicas;
        this.hashFunc = new HashFunc() {

            @Override
            public Long hash(Object key) {
//                return fnv1HashingAlg(key.toString());
                return md5HashingAlg(key.toString());
            }
        };
        //初始化节点
        for (T node : nodes) {
            add(node);
        }
    }

    /**
     * 构造
     * @param hashFunc         hash算法对象
     * @param numberOfReplicas 复制的节点个数，增加每个节点的复制节点有利于负载均衡
     * @param nodes            节点对象
     */
    public ConsistentHash(HashFunc hashFunc, int numberOfReplicas, Collection<T> nodes) {
        this.numberOfReplicas = numberOfReplicas;
        this.hashFunc = hashFunc;
        //初始化节点
        for (T node : nodes) {
            add(node);
        }
    }

    /**
     * 增加节点<br>
     * 每增加一个节点，就会在闭环上增加给定复制节点数<br>
     * 例如复制节点数是2，则每调用此方法一次，增加两个虚拟节点，这两个节点指向同一Node
     * 由于hash算法会调用node的toString方法，故按照toString去重
     *
     * @param node 节点对象
     */
    public void add(T node) {
        for (int i = 0; i < numberOfReplicas; i++) {
            circle.put(hashFunc.hash(node.toString() + i), node);
        }
    }

    /**
     * 移除节点的同时移除相应的虚拟节点
     *
     * @param node 节点对象
     */
    public void remove(T node) {
        for (int i = 0; i < numberOfReplicas; i++) {
            circle.remove(hashFunc.hash(node.toString() + i));
        }
    }

    /**
     * 获得一个最近的顺时针节点
     *
     * @param key 为给定键取Hash，取得顺时针方向上最近的一个虚拟节点对应的实际节点
     * @return 节点对象
     */
    public T get(Object key) {
        if (circle.isEmpty()) {
            return null;
        }
        long hash = hashFunc.hash(key);
        if (!circle.containsKey(hash)) {
            SortedMap<Long, T> tailMap = circle.tailMap(hash); //返回此映射的部分视图，其键大于等于 hash
            hash = tailMap.isEmpty() ? circle.firstKey() : tailMap.firstKey();
        }
        //正好命中
        return circle.get(hash);
    }

    /**
     * 使用MD5算法
     * @param key
     * @return
     */
    private static long md5HashingAlg(String key) {
        MessageDigest md5 = null;
        try {
            md5 = MessageDigest.getInstance("MD5");
            md5.reset();
            md5.update(key.getBytes());
            byte[] bKey = md5.digest();
            long res = ((long) (bKey[3] & 0xFF) << 24) | ((long) (bKey[2] & 0xFF) << 16) | ((long) (bKey[1] & 0xFF) << 8)| (long) (bKey[0] & 0xFF);
            return res;
        } catch (NoSuchAlgorithmException e) {
            e.printStackTrace();
        }
        return 0l;
    }

    /**
     * 使用FNV1hash算法
     * @param key
     * @return
     */
    private static long fnv1HashingAlg(String key) {
        final int p = 16777619;
        int hash = (int) 2166136261L;
        for (int i = 0; i < key.length(); i++)
            hash = (hash ^ key.charAt(i)) * p;
        hash += hash << 13;
        hash ^= hash >> 7;
        hash += hash << 3;
        hash ^= hash >> 17;
        hash += hash << 5;
        return hash;
    }

    /**
     * Hash算法对象，用于自定义hash算法
     */
    public interface HashFunc {
        public Long hash(Object key);
    }
}
```

​	Consistent Hashing最大限度地抑制了hash键的重新分布。另外要取得比较好的负载均衡的效果，往往在服务器数量比较少的时候需要增加虚拟节点来保证服务器能均匀的分布在圆环上。因为使用一般的hash方法，服务器的映射地点的分布非常不均匀。使用虚拟节点的思想，为每个物理节点（服务器）在圆上分配100～200个点。这样就能抑制分布不均匀，最大限度地减小服务器增减时的缓存重新分布。用户数据映射在虚拟节点上，就表示用户数据真正存储位置是在该虚拟节点代表的实际物理服务器上。 



# 18.最短路径之Dijkstra算法

​	Dijkstra算法是最短路径算法中为人熟知的一种，是单起点全路径算法。该算法被称为是“贪心算法”的成功典范。本文接下来将尝试以最通俗的语言来介绍这个伟大的算法，并赋予java实现代码。 

​	**知识准备**

​	1.表示图的数据结构

​		用于存储图的数据结构有多种，本算法中笔者使用的是邻接矩阵。 

​		图的邻接矩阵存储方式是用两个数组来表示图。一个一维数组存储图中顶点信息，一个二维数组（邻接矩阵）存储图中的边或弧的信息。 

​		设图G有n个顶点，则邻接矩阵是一个n*n的方阵，定义为： 

​			![](/images/011924154889072.png)



​		![](/images/011922477695708.png)

​		从上面可以看出，无向图的边数组是一个对称矩阵。所谓对称矩阵就是n阶矩阵的元满足aij = aji。即从矩阵的左上角到右下角的主对角线为轴，右上角的元和左下角相对应的元全都是相等的。 

​		从这个矩阵中，很容易知道图中的信息。

 		 （1）要判断任意两顶点是否有边无边就很容易了； 

​		 （2）要知道某个顶点的度，其实就是这个顶点vi在邻接矩阵中第i行或（第i列）的元素之和； 

​		 （3）求顶点vi的所有邻接点就是将矩阵中第i行元素扫描一遍，arc[i][j]为1就是邻接点 	

​	      而有向图讲究入度和出度，顶点vi的入度为1，正好是第i列各数之和。顶点vi的出度为2，即第i行的各数之和。 







